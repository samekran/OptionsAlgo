{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samekran/OptionsAlgo/blob/main/CallPuts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUxbeVmaSP74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "45d025cd-86cc-4a51-9ff5-240d54238ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter today's date: 05-24-2024\n",
            "Enter the expiration date: 05-31-2024\n",
            "Enter the time frame type (Enter $ for dollar return or % for percentage change): %\n",
            "Enter the time frame (1 mo, YTD, TTM, 2023, 2022, 2021, All): TTM\n",
            "Today's date: 05-24-2024\n",
            "Expiration date: 05-31-2024\n",
            "Time frame: 21\n"
          ]
        }
      ],
      "source": [
        "#@title Global Vars\n",
        "# Function to get user input for global variables\n",
        "def get_global_vars():\n",
        "    today_date_str = input(\"Enter today's date: \")\n",
        "    expr_date_str = input(\"Enter the expiration date: \")\n",
        "\n",
        "    time_frame_type = input(\"Enter the time frame type (Enter $ for dollar return or % for percentage change): \")\n",
        "    time_frame_str = input(\"Enter the time frame (1 mo, YTD, TTM, 2023, 2022, 2021, All): \")\n",
        "\n",
        "    time_frame_dict = {\n",
        "        \"$\": {\n",
        "            '1 mo': 10,\n",
        "            'YTD': 11,\n",
        "            'TTM': 12,\n",
        "            '2023': 13,\n",
        "            '2022': 14,\n",
        "            '2021': 15,\n",
        "            'All': 16\n",
        "        },\n",
        "        \"%\": {\n",
        "            '1 mo': 19,\n",
        "            'YTD': 20,\n",
        "            'TTM': 21,\n",
        "            '2023': 22,\n",
        "            '2022': 23,\n",
        "            '2021': 24,\n",
        "            'All': 25\n",
        "        }\n",
        "    }\n",
        "\n",
        "    time_frame = time_frame_dict[time_frame_type][time_frame_str]\n",
        "\n",
        "    return today_date_str, expr_date_str, time_frame\n",
        "\n",
        "# Get user input for global variables\n",
        "today_date_str, expr_date_str, time_frame = get_global_vars()\n",
        "\n",
        "print(f\"Today's date: {today_date_str}\")\n",
        "print(f\"Expiration date: {expr_date_str}\")\n",
        "print(f\"Time frame: {time_frame}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8HGKJFtdpVDX",
        "outputId": "16367f90-35b1-4a3f-ee73-906715199d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m102.4/107.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.2\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "#@title Installs\n",
        "# Import necessary libraries\n",
        "!pip install scikit-optimize\n",
        "!pip install openpyxl\n",
        "!pip install matplotlib PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fJEPXcOzV9c1"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skopt.space import Real, Categorical\n",
        "from skopt.utils import use_named_args\n",
        "from sklearn.model_selection import KFold\n",
        "from skopt import gp_minimize\n",
        "from datetime import datetime\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.styles import Alignment, PatternFill, Font\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import PyPDF2\n",
        "from collections import deque\n",
        "from joblib import Parallel, delayed\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "from itertools import product\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "collapsed": true,
        "id": "K39rclYuS-m6",
        "outputId": "ead2b087-00c0-4b26-aebf-ce58e0203f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the main data CSV file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ac3c1f5d-4132-435b-8c91-8d347dc577bb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ac3c1f5d-4132-435b-8c91-8d347dc577bb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Positive-5_pctchg_hibeta_sma20_4_0.25_30_N0_01_lower_2_2_NONE_0_below_timeline.csv to Positive-5_pctchg_hibeta_sma20_4_0.25_30_N0_01_lower_2_2_NONE_0_below_timeline.csv\n",
            "Please upload the zipped folder containing the option data files.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9d90543b-3a12-40ee-b0f7-8442db229454\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9d90543b-3a12-40ee-b0f7-8442db229454\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving updated_may_24_2024_optionsdata.zip to updated_may_24_2024_optionsdata.zip\n",
            "Files uploaded and unzipped successfully.\n"
          ]
        }
      ],
      "source": [
        "#@title Upload Files\n",
        "# Function to handle uploaded files\n",
        "def upload_file():\n",
        "    uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]  # Get the filename of the uploaded file\n",
        "    return file_path\n",
        "\n",
        "# Upload the main data file\n",
        "print(\"Please upload the main data CSV file.\")\n",
        "main_data_file_path = upload_file()\n",
        "\n",
        "# Upload the zipped folder containing the option data files\n",
        "print(\"Please upload the zipped folder containing the option data files.\")\n",
        "zipped_folder_path = upload_file()\n",
        "\n",
        "# Specify a directory name for the extracted files\n",
        "extracted_folder = '/content/option_data'\n",
        "\n",
        "# Unzip the folder\n",
        "with zipfile.ZipFile(zipped_folder_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder)\n",
        "\n",
        "print(\"Files uploaded and unzipped successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVuAZY_Orxwf",
        "outputId": "df102361-f8b9-45d7-a213-6b7c40e27242",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stocks in main CSV: ['AFRM', 'COIN', 'CFLT', 'CVNA', 'RIVN', 'TOST', 'CZR', 'W', 'PATH', 'RBLX', 'CAVA', 'DASH', 'SQ', 'CCL', 'MTDR', 'TTD', 'ON', 'NVDA', 'LNW', 'MPWR', 'GFS', 'LRCX', 'MKSI', 'MGM', 'OVV', 'ABNB', 'AMAT', 'CROX', 'DUOL', 'MSTR', 'RKT', 'MRVL', 'LSCC', 'BLDR', 'APA', 'AMD', 'KLAC', 'MCHP', 'DFS', 'FND', 'PINS', 'ENTG', 'GPS', 'AMP', 'WCC', 'HUBS', 'TSLA', 'PAYC', 'ONTO', 'XPO', 'DDS', 'TPR', 'WEX']\n",
            "Stocks in zip files: ['', 'PEP', 'AMGN', 'AVGO', 'DASH', 'MSTR', 'DFS', 'PATH', 'TSLA', 'AAPL', 'NVDA', 'MGM', 'CLF', 'CROX', 'MDB', 'XLC', 'LLY', 'VRTX', 'CCL', 'RKT', 'HOOD', 'TTD', 'APP', 'KLAC', 'IOT', 'PANW', 'MSFT', 'SPY', 'AFRM', 'COIN', 'W', 'C', 'NFLX', 'INTC', 'AMAT', 'FCX', 'SQ', 'SNOW', 'MRVL', 'META', 'RBLX', 'APA', 'ENPH', 'PLTR', 'XOM', 'U', 'CI', 'TPR', 'NVO', 'UNH', 'CZR', 'XLF', 'OXY', 'PINS', 'AMD', 'CVNA', 'ON', 'MS', 'GPS', 'GOOGL', 'XLY', 'RCL', 'ALGN', 'RIVN', 'XLK', 'JPM', 'GTLB', 'GS', 'ABNB', 'CAVA', 'CVX', 'TOST', 'MRNA', 'LRCX', 'KO']\n",
            "Combined list of stocks: ['ABNB', 'AFRM', 'AMAT', 'AMD', 'APA', 'CAVA', 'CCL', 'COIN', 'CROX', 'CVNA', 'CZR', 'DASH', 'DFS', 'GPS', 'KLAC', 'LRCX', 'MGM', 'MRVL', 'MSTR', 'NVDA', 'ON', 'PATH', 'PINS', 'RBLX', 'RIVN', 'RKT', 'SQ', 'TOST', 'TPR', 'TSLA', 'TTD', 'W']\n",
            "Option data filtered by volume successfully.\n"
          ]
        }
      ],
      "source": [
        "#@title Setup\n",
        "# Read the main data file\n",
        "df = pd.read_csv(main_data_file_path)\n",
        "\n",
        "# Get the list of stocks in the main CSV\n",
        "csv_stocks = [df.columns[i + 2].split('_')[0] for i in range(1, len(df.columns) - 4, 3)]\n",
        "print(f\"Stocks in main CSV: {csv_stocks}\")\n",
        "\n",
        "# Get the list of stocks in the zip files\n",
        "zip_stocks = set()\n",
        "for filename in os.listdir(extracted_folder):\n",
        "    stock_name = filename.split('_')[0]\n",
        "    zip_stocks.add(stock_name)\n",
        "zip_stocks = list(zip_stocks)\n",
        "print(f\"Stocks in zip files: {zip_stocks}\")\n",
        "\n",
        "# Find the intersection of stocks\n",
        "all_stocks = list(set(csv_stocks) & set(zip_stocks))\n",
        "all_stocks = sorted(all_stocks)\n",
        "print(f\"Combined list of stocks: {all_stocks}\")\n",
        "\n",
        "# Function to remove rows with volume less than 10% of the volume closest to the current price\n",
        "def filter_option_data_by_volume(extracted_folder, main_data_file_path, all_stocks):\n",
        "    # Read the main data file\n",
        "    main_df = pd.read_csv(main_data_file_path)\n",
        "\n",
        "    for stock in all_stocks:\n",
        "        # Get the current price for the stock\n",
        "        current_price = main_df[f'{stock}_adjclose'].iloc[0]\n",
        "\n",
        "        for filename in os.listdir(extracted_folder):\n",
        "            if filename.startswith(f\"{stock}_\"):\n",
        "                file_path = os.path.join(extracted_folder, filename)\n",
        "                df = pd.read_csv(file_path)\n",
        "\n",
        "                if 'strike' in df.columns and 'volume' in df.columns:\n",
        "\n",
        "                    # Filter out rows with NaN volumes\n",
        "                    df_filtered = df.dropna(subset=['volume'])\n",
        "\n",
        "                    # If the DataFrame is empty after filtering, skip to the next file\n",
        "                    if df_filtered.empty:\n",
        "                        print(f\"No rows with non-NaN volumes found for stock {stock}.\")\n",
        "                        continue\n",
        "\n",
        "                    # Find the closest strike price to the current price\n",
        "                    df_filtered = df_filtered.copy()  # Make a copy to avoid SettingWithCopyWarning\n",
        "                    df_filtered['diff'] = abs(df_filtered['strike'] - current_price)\n",
        "                    closest_strike_row = df_filtered.loc[df_filtered['diff'].idxmin()]\n",
        "                    closest_strike_volume = closest_strike_row['volume']\n",
        "\n",
        "                    # Calculate the volume threshold\n",
        "                    volume_threshold = 0.1 * closest_strike_volume\n",
        "\n",
        "                    # Filter the DataFrame\n",
        "                    df_filtered = df_filtered[df_filtered['volume'] >= volume_threshold]\n",
        "\n",
        "                    # Save the filtered DataFrame back to the file\n",
        "                    df_filtered.to_csv(file_path, index=False)\n",
        "\n",
        "    print(\"Option data filtered by volume successfully.\")\n",
        "\n",
        "# Filter the option data by volume\n",
        "filter_option_data_by_volume(extracted_folder, main_data_file_path, all_stocks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Filter Out Bad Signal Quality Stocks\n",
        "# Read the main data file\n",
        "df = pd.read_csv(main_data_file_path)\n",
        "\n",
        "# Get the number of standard deviations to consider\n",
        "num_std_dev = int(input(\"Enter the number of standard deviations (1 or 2): \"))\n",
        "\n",
        "# Calculate the number of relevant columns (total columns - 4 garbage columns)\n",
        "numCols = len(df.columns) - 4\n",
        "\n",
        "# Initialize dictionaries to store the results\n",
        "price_changes = {}\n",
        "signal_changes = {}\n",
        "\n",
        "# Calculate price changes\n",
        "for i in range(3, numCols, 3):\n",
        "    price_column = df.columns[i]\n",
        "    truncated_key = price_column.split('_')[0]\n",
        "    price_changes[truncated_key] = []\n",
        "\n",
        "    for j in range(len(df) - 5):\n",
        "        current_price = df.iloc[j, i]\n",
        "        future_price = df.iloc[j-5, i]\n",
        "        if pd.notna(current_price) and pd.notna(future_price) and current_price != 0:\n",
        "            percent_change = (future_price - current_price) / current_price * 100\n",
        "            price_changes[truncated_key].append(percent_change)\n",
        "\n",
        "# Calculate signal changes\n",
        "for i in range(1, numCols, 3):\n",
        "    signal_column = df.columns[i]\n",
        "    truncated_key = signal_column.split('_')[0]\n",
        "    signal_changes[truncated_key] = []\n",
        "\n",
        "    for j in range(len(df) - 5):\n",
        "        signal_value = df.iloc[j, i]\n",
        "        if signal_value == 1.0 and j > 4:\n",
        "            price_change = df.iloc[j, i + 1]\n",
        "            signal_changes[truncated_key].append(price_change)\n",
        "\n",
        "# Function to calculate percentages for given sigma\n",
        "def calculate_percentages(data, mean, std, sigma):\n",
        "    above_sigma = np.sum(np.array(data) > (mean + sigma * std)) / len(data) * 100\n",
        "    return above_sigma\n",
        "\n",
        "# Filter stocks based on signal quality\n",
        "stocks_to_keep = []\n",
        "\n",
        "threshold = float(input(\"Enter how much higher the signal tail should be (ex: 0.1 for 10%): \"))\n",
        "\n",
        "for key in all_stocks:\n",
        "    if key in signal_changes and key in price_changes:\n",
        "        price_data = price_changes[key]\n",
        "        signal_data = signal_changes[key]\n",
        "\n",
        "        mean_price = np.mean(price_data)\n",
        "        std_price = np.std(price_data)\n",
        "\n",
        "        price_above_sigma = calculate_percentages(price_data, mean_price, std_price, num_std_dev)\n",
        "        signal_above_sigma = calculate_percentages(signal_data, mean_price, std_price, num_std_dev)\n",
        "\n",
        "        if price_above_sigma != 0:\n",
        "            ratio = signal_above_sigma / price_above_sigma\n",
        "            if ratio >= 1+threshold:\n",
        "                stocks_to_keep.append(key)\n",
        "\n",
        "# Update the all_stocks list\n",
        "all_stocks = sorted(stocks_to_keep)\n",
        "\n",
        "print(f\"Filtered list of stocks: {all_stocks}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Fu4QGmSulbT9",
        "outputId": "09ae457f-0158-44aa-e116-85c73a80b58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of standard deviations (1 or 2): 2\n",
            "Enter how much higher the signal tail should be (ex: 0.1 for 10%): 0.1\n",
            "Filtered list of stocks: ['AAPL', 'ABNB', 'AFRM', 'AVGO', 'C', 'CCL', 'CI', 'CLF', 'COIN', 'CROX', 'CVX', 'DASH', 'DFS', 'GOOGL', 'GPS', 'GTLB', 'HOOD', 'INTC', 'KO', 'LLY', 'MGM', 'MRVL', 'MSTR', 'PANW', 'PATH', 'PEP', 'PINS', 'RBLX', 'RIVN', 'RKT', 'SPY', 'TOST', 'TPR', 'TSLA', 'TTD', 'UNH', 'XLC', 'XOM']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nKWAzW8zcniC",
        "outputId": "a8d5cc36-7f60-416a-e876-c53e4eba6059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "Updated CSV saved to updated_main_data.csv\n"
          ]
        }
      ],
      "source": [
        "#@title Change days\n",
        "# Function to calculate percent change for the specified day range\n",
        "def calculate_percent_change(df, days):\n",
        "    # Ensure the day range is valid\n",
        "    if days <= 0:\n",
        "        raise ValueError(\"Day range must be greater than 0.\")\n",
        "\n",
        "    # Iterate over each stock (assumed to be every 3 columns)\n",
        "    numCols = len(df.columns) - 4\n",
        "    for i in range(1, numCols, 3):\n",
        "        signal_col = df.columns[i]  # Signal column\n",
        "        pct_change_col = df.columns[i + 1]  # Percent change column\n",
        "        adj_close_col = df.columns[i + 2]  # Adjusted close column\n",
        "\n",
        "        # Initialize the pct change column\n",
        "        df[pct_change_col] = [np.nan] * len(df)\n",
        "\n",
        "        for j in range(len(df)):\n",
        "            if j >= days:\n",
        "                old_price = df.at[j, adj_close_col]\n",
        "                new_price = df.at[j - days, adj_close_col]\n",
        "                if old_price != 0:  # Avoid division by zero\n",
        "                    pct_change = (new_price - old_price) / old_price * 100\n",
        "                    df.at[j, pct_change_col] = pct_change\n",
        "                else:\n",
        "                    df.at[j, pct_change_col] = 0.0\n",
        "    return df\n",
        "\n",
        "# Function to calculate the number of weekdays between two dates\n",
        "def calculate_weekdays(start_date_str, end_date_str):\n",
        "    start_date = pd.to_datetime(start_date_str)\n",
        "    end_date = pd.to_datetime(end_date_str)\n",
        "    weekdays = pd.date_range(start=start_date, end=end_date, freq='B')\n",
        "    return len(weekdays)-1\n",
        "\n",
        "# Read the main data file\n",
        "df = pd.read_csv(main_data_file_path)\n",
        "\n",
        "# Calculate the number of weekdays between today_date_str and expr_date_str\n",
        "days = calculate_weekdays(today_date_str, expr_date_str)\n",
        "\n",
        "# Calculate percent change\n",
        "df = calculate_percent_change(df, days)\n",
        "\n",
        "print(days)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "main_data_file_path = 'updated_main_data.csv'\n",
        "df.to_csv(main_data_file_path, index=False)\n",
        "\n",
        "print(f\"Updated CSV saved to {main_data_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NjdYxUh5Rrv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title get_df\n",
        "def get_percents(ante_price, ticker, time_frame, dummy_df, all_days, call_buy=None, call_sell=None, put_sell=None, put_buy=None):\n",
        "    # Define a function to parse dates\n",
        "    def parse_dates(date):\n",
        "        for fmt in (\"%Y-%m-%d\", \"%m/%d/%y\"):\n",
        "            try:\n",
        "                return pd.to_datetime(date, format=fmt)\n",
        "            except ValueError:\n",
        "                continue\n",
        "        # If no format matches, raise an error\n",
        "        raise ValueError(f\"Date {date} is not in a recognized format\")\n",
        "\n",
        "    # Read the main data file\n",
        "    df = pd.read_csv(main_data_file_path)\n",
        "\n",
        "    # Parse the dates\n",
        "    df['date'] = df['date'].apply(parse_dates)\n",
        "\n",
        "    # Get the current date\n",
        "    current_date = df['date'].iloc[0]\n",
        "\n",
        "    # Filter data according to the time frame\n",
        "    if time_frame == '1 Mo':\n",
        "        start_date = current_date - pd.DateOffset(months=1)\n",
        "    elif time_frame == 'YTD':\n",
        "        start_date = pd.Timestamp(year=current_date.year, month=1, day=1)\n",
        "    elif time_frame == 'TTM':\n",
        "        start_date = current_date - pd.DateOffset(years=1)\n",
        "    elif time_frame == '2023':\n",
        "        start_date = pd.Timestamp(year=2023, month=1, day=1)\n",
        "        end_date = pd.Timestamp(year=2023, month=12, day=31)\n",
        "    elif time_frame == '2022':\n",
        "        start_date = pd.Timestamp(year=2022, month=1, day=1)\n",
        "        end_date = pd.Timestamp(year=2022, month=12, day=31)\n",
        "    elif time_frame == '2021':\n",
        "        start_date = pd.Timestamp(year=2021, month=1, day=1)\n",
        "        end_date = pd.Timestamp(year=2021, month=12, day=31)\n",
        "    elif time_frame == 'All':\n",
        "        start_date = df['date'].min()\n",
        "    else:\n",
        "        raise ValueError(\"Invalid time frame specified\")\n",
        "\n",
        "    # Apply the date filter\n",
        "    if time_frame in ['2023', '2022', '2021']:\n",
        "        df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
        "    else:\n",
        "        df = df[df['date'] >= start_date]\n",
        "\n",
        "    # Get the current price\n",
        "    current_price = df[f'{ticker}_adjclose'].iloc[-1]\n",
        "\n",
        "    # Initialize variables\n",
        "    win = 0.0\n",
        "    loss = 0.0\n",
        "    max_loss = 0.0\n",
        "    ante = 0.0\n",
        "\n",
        "    win_dollar = 0.0\n",
        "    loss_dollar = 0.0\n",
        "    max_loss_dollar = 0.0\n",
        "    ante_dollar = 0.0\n",
        "\n",
        "    win_count = 0\n",
        "    loss_count = 0\n",
        "    max_loss_count = 0\n",
        "    if dummy_df.iloc[5, 2] == 0:\n",
        "        return win, loss, max_loss, ante, win_dollar, loss_dollar, max_loss_dollar, ante_dollar, win_count, loss_count, max_loss_count\n",
        "\n",
        "    # Adjust for positive ante\n",
        "    if dummy_df.iloc[5, 1] > 0:\n",
        "        numerator = ante_price\n",
        "    else:\n",
        "        numerator = -ante_price\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        if all_days or row[f'{ticker}_signal_exists'] == 1:\n",
        "            pct_chg = row[f'{ticker}_5_pctchg'] / 100\n",
        "            conversion_rate = numerator / (float(dummy_df.iloc[5, 1]) * row[f'{ticker}_adjclose'])\n",
        "            total = 0.0\n",
        "            #Call buy\n",
        "            if call_buy is not None:\n",
        "                total += max(pct_chg-call_buy,0)\n",
        "            #Call sell\n",
        "            if call_sell is not None:\n",
        "                total -= max(pct_chg-call_sell,0)\n",
        "            #Put buy\n",
        "            if put_buy is not None:\n",
        "                total += max(put_buy-pct_chg,0)\n",
        "            #Put sell\n",
        "            if put_sell is not None:\n",
        "                total -= max(put_sell-pct_chg,0)\n",
        "\n",
        "            if total > 0:\n",
        "                win += total\n",
        "                win_dollar += total*row[f'{ticker}_adjclose'] * conversion_rate\n",
        "                win_count += 1\n",
        "\n",
        "            if total < 0:\n",
        "                loss += total\n",
        "                loss_dollar += total*row[f'{ticker}_adjclose'] * conversion_rate\n",
        "                loss_count += 1\n",
        "\n",
        "            ante += 1\n",
        "            ante_dollar += float(dummy_df.iloc[5, 2]) * row[f'{ticker}_adjclose']\n",
        "\n",
        "    return win, loss, max_loss, ante, win_dollar, loss_dollar, max_loss_dollar, ante_dollar, win_count, loss_count, max_loss_count\n",
        "\n",
        "def find_closest_strike(ticker, target_price, option_type, current_price):\n",
        "    closest_strike = None\n",
        "    closest_diff = float('inf')\n",
        "    average_bid_ask = None\n",
        "    option_type_alternatives = [option_type, option_type.lower() + 's']  # E.g., 'CALL' and 'calls' or 'PUT' and 'puts'\n",
        "\n",
        "    for filename in os.listdir(extracted_folder):\n",
        "        if any(f\"{ticker}_{today_date_str}_{alt}_exp_{expr_date_str}\" in filename for alt in option_type_alternatives):\n",
        "            file_path = os.path.join(extracted_folder, filename)\n",
        "            df = pd.read_csv(file_path)\n",
        "            if 'strike' in df.columns and 'bid' in df.columns and 'ask' in df.columns:\n",
        "                df['diff'] = abs(df['strike'] - target_price)\n",
        "                min_diff_row = df.loc[df['diff'].idxmin()]\n",
        "                if min_diff_row['diff'] < closest_diff:\n",
        "                    closest_diff = min_diff_row['diff']\n",
        "                    closest_strike = min_diff_row['strike']\n",
        "                    average_bid_ask = (min_diff_row['bid'] + min_diff_row['ask']) / 2\n",
        "\n",
        "    return closest_strike, average_bid_ask\n",
        "\n",
        "\n",
        "def get_df(ticker, call_buy=None, call_sell=None, put_sell=None, put_buy=None, all_days=False):\n",
        "    # Read the main data file\n",
        "    df = pd.read_csv(main_data_file_path)\n",
        "\n",
        "    # Get the current price from the most recent price in the [ticker]_adjclose column\n",
        "    current_price = df[f'{ticker}_adjclose'].iloc[0]\n",
        "\n",
        "    # Step 1: Define the headers\n",
        "    headers = [f'{ticker} Stock', 'Strike', '% change', '5 day option price', 'Column 5', 'Column 6']\n",
        "\n",
        "    # Step 2: Define the first column data\n",
        "    first_column_data = [\n",
        "        [\"Current price\"],\n",
        "        [\"Call Buy\"],\n",
        "        [\"Call Sell\"],\n",
        "        [\"Put 1 (sell)\"],\n",
        "        [\"Put 2 (buy)\"],\n",
        "        [\"Net Ante\"],\n",
        "        [\"\"],\n",
        "        [\"\"],\n",
        "        [\"Current Option Price\"],\n",
        "        [\"$100 Ante\"],\n",
        "        [\"1 Mo\"],\n",
        "        [\"YTD\"],\n",
        "        [\"TTM\"],\n",
        "        [\"2023\"],\n",
        "        [\"2022\"],\n",
        "        [\"2021\"],\n",
        "        [\"All\"],\n",
        "        [\"\"],\n",
        "        [\"Percent Change\"],\n",
        "        [\"1 Mo\"],\n",
        "        [\"YTD\"],\n",
        "        [\"TTM\"],\n",
        "        [\"2023\"],\n",
        "        [\"2022\"],\n",
        "        [\"2021\"],\n",
        "        [\"All\"],\n",
        "        [\"\"],\n",
        "        [\"Win Rate\"],\n",
        "        [\"1 Mo\"],\n",
        "        [\"YTD\"],\n",
        "        [\"TTM\"],\n",
        "        [\"2023\"],\n",
        "        [\"2022\"],\n",
        "        [\"2021\"],\n",
        "        [\"All\"]\n",
        "    ]\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    first_column_df = pd.DataFrame(first_column_data, columns=[f'{ticker} Stock'])\n",
        "\n",
        "    # Step 3: Create dummy data for the remaining columns\n",
        "    num_rows = len(first_column_data)\n",
        "    dummy_data = {\n",
        "        'Strike': [''] * num_rows,\n",
        "        '% change': [''] * num_rows,\n",
        "        '5 day option price': [''] * num_rows,\n",
        "        'Column 5': [''] * num_rows,\n",
        "        'Column 6': [''] * num_rows\n",
        "    }\n",
        "\n",
        "    # Find the closest strikes and average bid/ask for the given targets\n",
        "    call_buy_target_price = current_price * (1 + call_buy) if call_buy is not None else None\n",
        "    closest_call_buy_strike, average_call_buy_bid_ask = find_closest_strike(ticker, call_buy_target_price, 'CALL', current_price) if call_buy is not None else (None, None)\n",
        "\n",
        "    call_sell_target_price = current_price * (1 + call_sell) if call_sell is not None else None\n",
        "    closest_call_sell_strike, average_call_sell_bid_ask = find_closest_strike(ticker, call_sell_target_price, 'CALL', current_price) if call_sell is not None else (None, None)\n",
        "\n",
        "    putsell_target_price = current_price * (1 + put_sell) if put_sell is not None else None\n",
        "    closest_putsell_strike, average_putsell_bid_ask = find_closest_strike(ticker, putsell_target_price, 'PUT', current_price) if put_sell is not None else (None, None)\n",
        "\n",
        "    putbuy_target_price = current_price * (1 + put_buy) if put_buy is not None else None\n",
        "    closest_putbuy_strike, average_putbuy_bid_ask = find_closest_strike(ticker, putbuy_target_price,'PUT', current_price) if put_buy is not None else (None, None)\n",
        "\n",
        "    # Convert dummy data to DataFrame\n",
        "    dummy_df = pd.DataFrame(dummy_data)\n",
        "    dummy_df.at[0, 'Strike'] = current_price\n",
        "\n",
        "    # Assign values to specific cells\n",
        "    if call_buy is not None:\n",
        "        dummy_df.at[1, 'Strike'] = closest_call_buy_strike\n",
        "        dummy_df.at[1, '5 day option price'] = average_call_buy_bid_ask\n",
        "        dummy_df.at[1, '% change'] = closest_call_buy_strike / current_price - 1\n",
        "\n",
        "    if call_sell is not None:\n",
        "        dummy_df.at[2, 'Strike'] = closest_call_sell_strike\n",
        "        dummy_df.at[2, '5 day option price'] = average_call_sell_bid_ask\n",
        "        dummy_df.at[2, '% change'] = closest_call_sell_strike / current_price - 1\n",
        "\n",
        "    if put_sell is not None:\n",
        "        dummy_df.at[3, 'Strike'] = closest_putsell_strike\n",
        "        dummy_df.at[3, '5 day option price'] = average_putsell_bid_ask\n",
        "        dummy_df.at[3, '% change'] = closest_putsell_strike / current_price - 1\n",
        "\n",
        "    if put_buy is not None:\n",
        "        dummy_df.at[4, 'Strike'] = closest_putbuy_strike\n",
        "        dummy_df.at[4, '5 day option price'] = average_putbuy_bid_ask\n",
        "        dummy_df.at[4, '% change'] = closest_putbuy_strike / current_price - 1\n",
        "\n",
        "    # Net ante\n",
        "    dummy_df.at[5, '5 day option price'] = (\n",
        "        (float(dummy_df.at[3, '5 day option price']) if put_sell is not None and dummy_df.at[3, '5 day option price'] else 0)\n",
        "        - (float(dummy_df.at[1, '5 day option price']) if call_buy is not None and dummy_df.at[1, '5 day option price'] else 0)\n",
        "        - (float(dummy_df.at[4, '5 day option price']) if put_buy is not None and dummy_df.at[4, '5 day option price'] else 0)\n",
        "        + (float(dummy_df.at[2, '5 day option price']) if call_sell is not None and dummy_df.at[2, '5 day option price'] else 0)\n",
        "    )\n",
        "    dummy_df.at[5, '% change'] = float(dummy_df.at[5, '5 day option price']) / float(dummy_df.at[0, 'Strike']) if dummy_df.at[0, 'Strike'] else 0.0\n",
        "\n",
        "    # Define the time frames to process\n",
        "    time_frames = ['1 Mo', 'YTD', 'TTM', '2023', '2022', '2021', 'All']\n",
        "    row_mapping = {\n",
        "        '1 Mo': 19,\n",
        "        'YTD': 20,\n",
        "        'TTM': 21,\n",
        "        '2023': 22,\n",
        "        '2022': 23,\n",
        "        '2021': 24,\n",
        "        'All': 25\n",
        "    }\n",
        "\n",
        "    row_mapping_dollar = {\n",
        "        '1 Mo': 10,\n",
        "        'YTD': 11,\n",
        "        'TTM': 12,\n",
        "        '2023': 13,\n",
        "        '2022': 14,\n",
        "        '2021': 15,\n",
        "        'All': 16\n",
        "    }\n",
        "\n",
        "    row_mapping_rate = {\n",
        "        '1 Mo': 28,\n",
        "        'YTD': 29,\n",
        "        'TTM': 30,\n",
        "        '2023': 31,\n",
        "        '2022': 32,\n",
        "        '2021': 33,\n",
        "        'All': 34\n",
        "    }\n",
        "\n",
        "    ante_price = 100\n",
        "    flag = True\n",
        "    while flag:\n",
        "        flag = False\n",
        "        for time_frame in time_frames:\n",
        "            win, loss, max_loss, ante, win_dollar, loss_dollar, max_loss_dollar, ante_dollar, win_count, loss_count, max_loss_count = get_percents(ante_price, ticker, time_frame, dummy_df, all_days, call_buy, call_sell, put_sell, put_buy)\n",
        "            if np.abs(max_loss_dollar) > 3 * np.abs(ante_dollar):\n",
        "                flag = True\n",
        "                break\n",
        "            row = row_mapping[time_frame]\n",
        "            dummy_df.at[row, 'Strike'] = win\n",
        "            dummy_df.at[row, '% change'] = loss\n",
        "            dummy_df.at[row, '5 day option price'] = max_loss\n",
        "            dummy_df.at[row, 'Column 5'] = ante\n",
        "\n",
        "            row_dollar = row_mapping_dollar[time_frame]\n",
        "            dummy_df.at[row_dollar, 'Strike'] = win_dollar\n",
        "            dummy_df.at[row_dollar, '% change'] = loss_dollar\n",
        "            dummy_df.at[row_dollar, '5 day option price'] = max_loss_dollar\n",
        "            dummy_df.at[row_dollar, 'Column 5'] = ante_dollar\n",
        "\n",
        "            row_rate = row_mapping_rate[time_frame]\n",
        "            total = win_count + loss_count + max_loss_count\n",
        "            if total != 0:\n",
        "                dummy_df.at[row_rate, 'Strike'] = win_count / total\n",
        "                dummy_df.at[row_rate, '% change'] = loss_count / total\n",
        "                dummy_df.at[row_rate, '5 day option price'] = max_loss_count / total\n",
        "\n",
        "        if flag:\n",
        "            ante_price = ante_dollar / (3 * max_loss_dollar)\n",
        "\n",
        "    # Get percent totals\n",
        "    for i in range(19, 26):\n",
        "        total = 0\n",
        "        for j in range(0, 4):\n",
        "            try:\n",
        "                if j == 3:\n",
        "                    total += float(dummy_df.iloc[i, j]) * dummy_df.iloc[5, 1]\n",
        "                else:\n",
        "                    total += float(dummy_df.iloc[i, j])\n",
        "            except ValueError:\n",
        "                continue  # Skip non-numeric values\n",
        "        dummy_df.at[i, 'Column 6'] = total\n",
        "\n",
        "    # $100 Ante\n",
        "    for i in range(10, 17):\n",
        "        if dummy_df.iloc[5, 1] > 0:\n",
        "            dummy_df.at[i, 'Column 5'] = 100 * dummy_df.at[i + 9, 'Column 5']\n",
        "        else:\n",
        "            dummy_df.at[i, 'Column 5'] = -100 * dummy_df.at[i + 9, 'Column 5']\n",
        "\n",
        "    # Get price totals\n",
        "    for i in range(10, 17):\n",
        "        total = 0\n",
        "        for j in range(0, 4):\n",
        "            try:\n",
        "                total += float(dummy_df.iloc[i, j])\n",
        "            except ValueError:\n",
        "                continue  # Skip non-numeric values\n",
        "        dummy_df.at[i, 'Column 6'] = total\n",
        "\n",
        "    dummy_df.iloc[9, 0] = 'Win $'\n",
        "    dummy_df.iloc[9, 1] = 'Loss $'\n",
        "    dummy_df.iloc[9, 2] = 'Max Loss $'\n",
        "    dummy_df.iloc[9, 3] = 'Ante $'\n",
        "    dummy_df.iloc[9, 4] = 'Net $'\n",
        "\n",
        "    dummy_df.iloc[18, 0] = 'Win %'\n",
        "    dummy_df.iloc[18, 1] = 'Loss %'\n",
        "    dummy_df.iloc[18, 2] = 'Max Loss %'\n",
        "    dummy_df.iloc[18, 3] = 'Ante #'\n",
        "    dummy_df.iloc[18, 4] = 'Net %'\n",
        "\n",
        "    dummy_df.iloc[27, 0] = 'Win %'\n",
        "    dummy_df.iloc[27, 1] = 'Loss %'\n",
        "    dummy_df.iloc[27, 2] = 'Max Loss %'\n",
        "\n",
        "    # Step 4: Combine the first column DataFrame with the dummy data DataFrame\n",
        "    combined_df = pd.concat([first_column_df, dummy_df], axis=1)\n",
        "\n",
        "    # Add headers to the combined DataFrame\n",
        "    combined_df.columns = headers\n",
        "\n",
        "    return combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "en-Vb2PwfI_l"
      },
      "outputs": [],
      "source": [
        "#@title portfolio optimize\n",
        "def portfolio_optimize(all_days):\n",
        "\n",
        "    # Define the parameter space\n",
        "    space = [\n",
        "        Categorical([None] + list(np.linspace(0.005, 0.2, num=20)), name='call_buy'),\n",
        "        Categorical([None] + list(np.linspace(-0.2, -0.01, num=20)), name='call_sell'),\n",
        "        Categorical([None] + list(np.linspace(-0.1, -0.01, num=10)), name='put_sell'),\n",
        "        Categorical([None] + list(np.linspace(-0.2, -0.01, num=20)), name='put_buy')\n",
        "    ]\n",
        "\n",
        "    def run_analysis(stocks, call_buy, call_sell, put_sell, put_buy, time_frame):\n",
        "        gain_values_pos_ante = []\n",
        "        gain_values_neg_ante = []\n",
        "\n",
        "        # Define the function to process each stock\n",
        "        def process_stock(stock):\n",
        "            stock_df = get_df(stock, call_buy, call_sell, put_sell, put_buy, all_days)\n",
        "            if stock_df is not None:\n",
        "                try:\n",
        "                    ante_value = stock_df.iloc[5, 2]\n",
        "                    gain_value = stock_df.iloc[time_frame, 5]\n",
        "                    # Check if the ante value is negative\n",
        "                    if ante_value < 0:\n",
        "                        return None, gain_value\n",
        "                    else:\n",
        "                        return gain_value, None\n",
        "                except (IndexError, KeyError):\n",
        "                    return None, None\n",
        "            return None, None\n",
        "\n",
        "        # Use parallel processing to process stocks\n",
        "        results = Parallel(n_jobs=-1)(delayed(process_stock)(stock) for stock in stocks)\n",
        "        #results = [process_stock(stock) for stock in stocks]\n",
        "\n",
        "        # Separate positive and negative ante results\n",
        "        for gain_pos, gain_neg in results:\n",
        "            if gain_pos is not None:\n",
        "                gain_values_pos_ante.append(gain_pos)\n",
        "            if gain_neg is not None:\n",
        "                gain_values_neg_ante.append(gain_neg)\n",
        "\n",
        "        # Calculate the average gain value for positive ante\n",
        "        if gain_values_pos_ante:\n",
        "            average_gain_pos_ante = sum(gain_values_pos_ante) / len(gain_values_pos_ante)\n",
        "        else:\n",
        "            average_gain_pos_ante = None\n",
        "\n",
        "        # Calculate the average gain value for negative ante\n",
        "        if gain_values_neg_ante:\n",
        "            average_gain_neg_ante = sum(gain_values_neg_ante) / len(gain_values_neg_ante)\n",
        "        else:\n",
        "            average_gain_neg_ante = None\n",
        "\n",
        "        return average_gain_pos_ante, average_gain_neg_ante\n",
        "\n",
        "    # Split the stocks into training and validation sets\n",
        "    train_stocks, val_stocks = train_test_split(all_stocks, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define the objective function for positive ante\n",
        "    @use_named_args(space)\n",
        "    def objective_pos_ante(**params):\n",
        "        call_buy = params.get('call_buy', None)\n",
        "        call_sell = params.get('call_sell', None)\n",
        "        put_sell = params.get('put_sell', None)\n",
        "        put_buy = params.get('put_buy', None)\n",
        "        # Ensure valid combinations of options\n",
        "        if call_buy is None or (call_sell is not None and call_sell >= call_buy) or put_buy is None:\n",
        "            return 0.0\n",
        "\n",
        "        gain_pos_ante, _ = run_analysis(train_stocks, call_buy, call_sell, put_sell, put_buy, time_frame)\n",
        "        if not isinstance(gain_pos_ante, (int, float)) or np.isnan(gain_pos_ante):\n",
        "            return 0.0\n",
        "        return -gain_pos_ante  # Minimize negative gain to maximize gain\n",
        "\n",
        "    # Define the objective function for negative ante\n",
        "    @use_named_args(space)\n",
        "    def objective_neg_ante(**params):\n",
        "        call_buy = params.get('call_buy', None)\n",
        "        call_sell = params.get('call_sell', None)\n",
        "        put_sell = params.get('put_sell', None)\n",
        "        put_buy = params.get('put_buy', None)\n",
        "        # Ensure valid combinations of options\n",
        "        if call_buy is None or (call_sell is not None and call_sell >= call_buy) or put_buy is None:\n",
        "            return 0.0\n",
        "\n",
        "        _, gain_neg_ante = run_analysis(train_stocks, call_buy, call_sell, put_sell, put_buy, time_frame)\n",
        "        if not isinstance(gain_neg_ante, (int, float)) or np.isnan(gain_neg_ante):\n",
        "            return 0.0\n",
        "        return -gain_neg_ante  # Minimize negative gain to maximize gain\n",
        "\n",
        "    # Perform Bayesian optimization for positive ante\n",
        "    result_pos_ante = gp_minimize(objective_pos_ante, space, n_calls=30, random_state=0)\n",
        "    print(\"Best parameters found for positive ante: call_buy={}, call_sell={}, put_sell={}, put_buy={}\".format(result_pos_ante.x[0], result_pos_ante.x[1], result_pos_ante.x[2], result_pos_ante.x[3]))\n",
        "    train_gain_pos_ante, _ = run_analysis(train_stocks, result_pos_ante.x[0], result_pos_ante.x[1], result_pos_ante.x[2], result_pos_ante.x[3], time_frame)\n",
        "    print(f\"Average gain after ante for training set with positive ante: {train_gain_pos_ante}\")\n",
        "\n",
        "    # Perform Bayesian optimization for negative ante\n",
        "    result_neg_ante = gp_minimize(objective_neg_ante, space, n_calls=30, random_state=0)\n",
        "    print(\"Best parameters found for negative ante: call_buy={}, call_sell={}, put_sell={}, put_buy={}\".format(result_neg_ante.x[0], result_neg_ante.x[1], result_neg_ante.x[2], result_neg_ante.x[3]))\n",
        "    _, train_gain_neg_ante = run_analysis(train_stocks, result_neg_ante.x[0], result_neg_ante.x[1], result_neg_ante.x[2], result_neg_ante.x[3], time_frame)\n",
        "    print(f\"Average gain after ante for training set with negative ante: {train_gain_neg_ante}\")\n",
        "\n",
        "    # Validate on the remaining 20% stocks\n",
        "    val_gain_pos_ante = run_analysis(val_stocks, result_pos_ante.x[0], result_pos_ante.x[1], result_pos_ante.x[2], result_pos_ante.x[3], time_frame)\n",
        "    val_gain_neg_ante = run_analysis(val_stocks, result_neg_ante.x[0], result_neg_ante.x[1], result_neg_ante.x[2], result_neg_ante.x[3], time_frame)\n",
        "    print(f\"Validation gain after ante for validation set with positive ante: {val_gain_pos_ante[0]}\")\n",
        "    print(f\"Validation gain after ante for validation set with negative ante: {val_gain_neg_ante[1]}\")\n",
        "\n",
        "    return train_gain_pos_ante, train_gain_neg_ante, val_gain_pos_ante, val_gain_neg_ante, result_pos_ante.x[0], result_pos_ante.x[1], result_pos_ante.x[2], result_pos_ante.x[3], result_neg_ante.x[0], result_neg_ante.x[1], result_neg_ante.x[2], result_neg_ante.x[3]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run portfolio optimize\n",
        "train_gain_pos_ante, train_gain_neg_ante, val_gain_pos_ante, val_gain_neg_ante, poscallbuy, poscallsell, posputsell, posputbuy, negcallbuy, negcallsell, negputsell, negputbuy = portfolio_optimize(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "collapsed": true,
        "cellView": "form",
        "id": "3N2k2AM-xK6y",
        "outputId": "44ee82db-52ad-40bd-8686-e70b960b6c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for /: 'NoneType' and 'float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"<ipython-input-64-658b605630b5>\", line 18, in process_stock\n  File \"<ipython-input-62-f689eed608a0>\", line 201, in get_df\nTypeError: unsupported operand type(s) for /: 'NoneType' and 'float'\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-708b07478c19>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title run portfolio optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_gain_pos_ante\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gain_neg_ante\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gain_pos_ante\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gain_neg_ante\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposcallbuy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposcallsell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposputsell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposputbuy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegcallbuy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegcallsell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegputsell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegputbuy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mportfolio_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-658b605630b5>\u001b[0m in \u001b[0;36mportfolio_optimize\u001b[0;34m(all_days)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Perform Bayesian optimization for positive ante\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mresult_pos_ante\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_pos_ante\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters found for positive ante: call_buy={}, call_sell={}, put_sell={}, put_buy={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_pos_ante\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_pos_ante\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_pos_ante\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_pos_ante\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mtrain_gain_pos_ante\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_pos_ante\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_pos_ante\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_pos_ante\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_pos_ante\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-658b605630b5>\u001b[0m in \u001b[0;36mobjective_pos_ante\u001b[0;34m(**params)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mgain_pos_ante\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_buy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_sell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mput_sell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mput_buy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgain_pos_ante\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgain_pos_ante\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-658b605630b5>\u001b[0m in \u001b[0;36mrun_analysis\u001b[0;34m(stocks, call_buy, call_sell, put_sell, put_buy, time_frame)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Use parallel processing to process stocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_stock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m#results = [process_stock(stock) for stock in stocks]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NzVhPjcedY1g",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title individual optimize\n",
        "def individual_optimize(all_days):\n",
        "    def split_stock_df(df, stock_name):\n",
        "        signal_indices = df.index[df[f'{stock_name}_signal_exists'] == 1].tolist()\n",
        "        num_signals = len(signal_indices)\n",
        "        if num_signals < 10:\n",
        "            return None, None\n",
        "\n",
        "        split_index = int(0.8 * num_signals)\n",
        "        train_indices = signal_indices[:split_index]\n",
        "        val_indices = signal_indices[split_index:]\n",
        "\n",
        "        train_df = df.loc[train_indices].reset_index(drop=True)\n",
        "        val_df = df.loc[val_indices].reset_index(drop=True)\n",
        "\n",
        "        return train_df, val_df\n",
        "\n",
        "    def run_analysis(stock_name, call_buy, call_sell, put_sell, put_buy, time_frame, all_days):\n",
        "        stock_df = get_df(stock_name, call_buy, call_sell, put_sell, put_buy, all_days=all_days)\n",
        "        if stock_df is not None:\n",
        "            gain_value = stock_df.iloc[time_frame, 5]\n",
        "            return gain_value\n",
        "        return np.nan\n",
        "\n",
        "    def optimize_for_stock(stock_name, train_df, val_df, combination, all_days):\n",
        "        # Define the parameter space for the specific combination\n",
        "        space = []\n",
        "        if 'call_buy' in combination:\n",
        "            space.append(Categorical(list(np.linspace(0.005, 0.2, num=20)), name='call_buy'))\n",
        "        if 'call_sell' in combination:\n",
        "            space.append(Categorical(list(np.linspace(-0.2, -0.01, num=20)), name='call_sell'))\n",
        "        if 'put_sell' in combination:\n",
        "            space.append(Categorical(list(np.linspace(-0.1, -0.01, num=10)), name='put_sell'))\n",
        "        if 'put_buy' in combination:\n",
        "            space.append(Categorical(list(np.linspace(-0.2, -0.01, num=20)), name='put_buy'))\n",
        "\n",
        "        @use_named_args(space)\n",
        "        def objective(**params):\n",
        "            call_buy = params.get('call_buy', None)\n",
        "            call_sell = params.get('call_sell', None)\n",
        "            put_sell = params.get('put_sell', None)\n",
        "            put_buy = params.get('put_buy', None)\n",
        "\n",
        "            # Enforce constraints\n",
        "            if call_buy is None or (call_sell is not None and call_sell >= call_buy) or put_buy is None:\n",
        "                return 0.0\n",
        "\n",
        "            gain = run_analysis(stock_name, call_buy, call_sell, put_sell, put_buy, time_frame, all_days)\n",
        "            if np.isnan(gain):\n",
        "                return 0.0\n",
        "            return -gain\n",
        "\n",
        "        result = gp_minimize(objective, space, n_calls=10, random_state=42)\n",
        "\n",
        "        # Map the result back to the appropriate parameters\n",
        "        call_buy_opt = None\n",
        "        call_sell_opt = None\n",
        "        put_sell_opt = None\n",
        "        put_buy_opt = None\n",
        "\n",
        "        result_index = 0\n",
        "        if 'call_buy' in combination:\n",
        "            call_buy_opt = result.x[result_index]\n",
        "            result_index += 1\n",
        "        if 'call_sell' in combination:\n",
        "            call_sell_opt = result.x[result_index]\n",
        "            result_index += 1\n",
        "        if 'put_sell' in combination:\n",
        "            put_sell_opt = result.x[result_index]\n",
        "            result_index += 1\n",
        "        if 'put_buy' in combination:\n",
        "            put_buy_opt = result.x[result_index]\n",
        "\n",
        "        val_gain = run_analysis(stock_name, call_buy_opt, call_sell_opt, put_sell_opt, put_buy_opt, time_frame, all_days)\n",
        "        if np.isnan(val_gain):\n",
        "            val_gain = 0.0  # Ensure no NaN values\n",
        "        return call_buy_opt, call_sell_opt, put_sell_opt, put_buy_opt, val_gain\n",
        "\n",
        "    def process_stock(stock, all_days):\n",
        "        train_df, val_df = split_stock_df(df, stock)\n",
        "        if train_df is not None and val_df is not None:\n",
        "            best_combination = None\n",
        "            best_gain = -float('inf')\n",
        "            best_params = None\n",
        "\n",
        "            # Define the valid combinations\n",
        "            valid_combinations = [\n",
        "                ['call_buy', 'put_buy'],\n",
        "                ['call_buy', 'call_sell', 'put_buy'],\n",
        "                ['call_buy', 'put_sell', 'put_buy'],\n",
        "                ['call_buy', 'call_sell', 'put_sell', 'put_buy']\n",
        "            ]\n",
        "\n",
        "            for combination in valid_combinations:\n",
        "                params = optimize_for_stock(stock, train_df, val_df, combination, all_days)\n",
        "                if params[4] > best_gain:\n",
        "                    best_gain = params[4]\n",
        "                    best_params = params\n",
        "                    best_combination = combination\n",
        "\n",
        "            return best_params\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    optimized_params = {}\n",
        "    validation_gains = []\n",
        "\n",
        "    df = pd.read_csv(main_data_file_path)  # Load the main data file\n",
        "\n",
        "    # Use parallel computing to optimize for each stock\n",
        "    results = Parallel(n_jobs=-1)(delayed(process_stock)(stock, all_days) for stock in all_stocks)\n",
        "\n",
        "    for stock, result in zip(all_stocks, results):\n",
        "        if result is not None:\n",
        "            call_buy_opt, call_sell_opt, put_sell_opt, put_buy_opt, val_gain = result\n",
        "            if not np.isnan(val_gain):\n",
        "                optimized_params[stock] = (call_buy_opt, call_sell_opt, put_sell_opt, put_buy_opt)\n",
        "                validation_gains.append(val_gain)\n",
        "            else:\n",
        "                print(f\"Stock {stock} returned a NaN validation gain\")\n",
        "        else:\n",
        "            print(f\"Stock {stock} optimization returned None\")\n",
        "\n",
        "    if validation_gains:\n",
        "        average_validation_gain = sum(validation_gains) / len(validation_gains)\n",
        "    else:\n",
        "        average_validation_gain = np.nan\n",
        "\n",
        "    print(f\"Average gain after ante for validation sets across all stocks: {average_validation_gain}\")\n",
        "\n",
        "    return optimized_params, validation_gains, average_validation_gain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run individual optimize\n",
        "optimized_params, validation_gains, average_validation_gain = individual_optimize(all_days=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H_qMeU2bzUC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title debugging\n",
        "# Find stocks that are in optimized_params.keys() but not in all_stocks\n",
        "missing_stocks = set(optimized_params.keys()) - set(all_stocks)\n",
        "\n",
        "# Print the missing stocks\n",
        "if len(missing_stocks) == 0:\n",
        "  print(\"All stocks accounted for\")\n",
        "else:\n",
        "  print(\"Missing stocks:\")\n",
        "  for stock in missing_stocks:\n",
        "      print(stock)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VnAl1ETQxX7H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title manual optimize\n",
        "def manual_optimize(all_days):\n",
        "    # Define the parameter space with constraints\n",
        "    def get_constrained_strikes(extracted_folder, ticker, option_type, current_price, max_steps=3):\n",
        "        strikes = set()\n",
        "        for filename in os.listdir(extracted_folder):\n",
        "            parts = filename.split('_')\n",
        "            if len(parts) >= 4 and parts[0] == ticker and parts[2] == option_type:\n",
        "                file_path = os.path.join(extracted_folder, filename)\n",
        "                df = pd.read_csv(file_path)\n",
        "                if 'strike' in df.columns:\n",
        "                    strikes.update(df['strike'].tolist())\n",
        "\n",
        "        sorted_strikes = sorted(list(strikes))\n",
        "        constrained_strikes = []\n",
        "\n",
        "        for strike in sorted_strikes:\n",
        "            if option_type == 'CALL' and strike > current_price:\n",
        "                constrained_strikes.append(strike)\n",
        "            elif option_type == 'PUT' and strike < current_price:\n",
        "                constrained_strikes.append(strike)\n",
        "\n",
        "            # Check if the number of steps is within the limit\n",
        "            if len(constrained_strikes) > max_steps:\n",
        "                break\n",
        "\n",
        "        return [None] + constrained_strikes\n",
        "\n",
        "    # Get available strikes for each ticker with constraints\n",
        "    def get_all_constrained_strikes(extracted_folder, all_stocks, main_data_file_path):\n",
        "        main_df = pd.read_csv(main_data_file_path)\n",
        "        available_strikes = {}\n",
        "        for stock in all_stocks:\n",
        "            current_price = main_df[f'{stock}_adjclose'].iloc[0]\n",
        "            available_strikes[stock] = {\n",
        "                'CALL': get_constrained_strikes(extracted_folder, stock, 'CALL', current_price),\n",
        "                'PUT': get_constrained_strikes(extracted_folder, stock, 'PUT', current_price)\n",
        "            }\n",
        "        return available_strikes\n",
        "\n",
        "    available_strikes = get_all_constrained_strikes(extracted_folder, all_stocks, main_data_file_path)\n",
        "\n",
        "    def run_analysis(stock_name, call_buy, put_sell, put_buy, time_frame, all_days):\n",
        "        stock_df = get_df(stock_name, call_buy, None, put_sell, put_buy, all_days=all_days)\n",
        "        if stock_df is not None:\n",
        "            gain_value = stock_df.iloc[time_frame, 5]\n",
        "            return gain_value\n",
        "        return np.nan\n",
        "\n",
        "    def optimize_for_stock(stock_name, current_price, train_df, val_df, all_days):\n",
        "        # Get the available strikes for the stock with constraints\n",
        "        call_strikes = available_strikes[stock_name]['CALL']\n",
        "        put_strikes = available_strikes[stock_name]['PUT']\n",
        "\n",
        "        best_params = None\n",
        "        best_gain = -float('inf')\n",
        "\n",
        "        # Try all combinations of strikes including None\n",
        "        for call_buy, put_sell, put_buy in product(call_strikes, put_strikes, put_strikes):\n",
        "            if call_buy is not None:\n",
        "                call_buy_pct = (call_buy / current_price) - 1\n",
        "            else:\n",
        "                call_buy_pct = None\n",
        "\n",
        "            if put_sell is not None:\n",
        "                put_sell_pct = (put_sell / current_price) - 1\n",
        "            else:\n",
        "                put_sell_pct = None\n",
        "\n",
        "            if put_buy is not None:\n",
        "                put_buy_pct = (put_buy / current_price) - 1\n",
        "            else:\n",
        "                put_buy_pct = None\n",
        "\n",
        "            # Ensure put buy is lower than put sell and constraints are met\n",
        "            if call_buy is not None and put_sell is not None and put_buy is not None:\n",
        "                if (call_buy > current_price) and (put_sell < current_price) and (put_buy < current_price) and (put_buy < put_sell):\n",
        "                    gain = run_analysis(stock_name, call_buy_pct, put_sell_pct, put_buy_pct, time_frame, all_days)\n",
        "                    if not np.isnan(gain) and gain > best_gain:\n",
        "                        best_gain = gain\n",
        "                        best_params = (call_buy_pct, put_sell_pct, put_buy_pct)\n",
        "\n",
        "        if best_params is not None:\n",
        "            return *best_params, best_gain\n",
        "        else:\n",
        "            return None, None, None, best_gain\n",
        "\n",
        "\n",
        "\n",
        "    def split_stock_df(df, stock_name):\n",
        "        signal_indices = df.index[df[f'{stock_name}_signal_exists'] == 1].tolist()\n",
        "        num_signals = len(signal_indices)\n",
        "        if num_signals < 10:\n",
        "            return None, None\n",
        "\n",
        "        split_index = int(0.8 * num_signals)\n",
        "        train_indices = signal_indices[:split_index]\n",
        "        val_indices = signal_indices[split_index:]\n",
        "\n",
        "        train_df = df.loc[train_indices].reset_index(drop=True)\n",
        "        val_df = df.loc[val_indices].reset_index(drop=True)\n",
        "\n",
        "        return train_df, val_df\n",
        "\n",
        "    # Perform the optimization for each stock\n",
        "    manual_params = {}\n",
        "    manual_validation_gains = []\n",
        "\n",
        "    df = pd.read_csv(main_data_file_path)  # Load the main data file\n",
        "\n",
        "    for stock in all_stocks:\n",
        "        current_price = df[f'{stock}_adjclose'].iloc[0]\n",
        "        train_df, val_df = split_stock_df(df, stock)\n",
        "        if train_df is not None and val_df is not None:\n",
        "            result = optimize_for_stock(stock, current_price, train_df, val_df, all_days)\n",
        "            if result is not None:\n",
        "                call_buy_opt, put_sell_opt, put_buy_opt, val_gain = result\n",
        "                if not np.isnan(val_gain):\n",
        "                    manual_params[stock] = (call_buy_opt, put_sell_opt, put_buy_opt)\n",
        "                    manual_validation_gains.append(val_gain)\n",
        "                else:\n",
        "                    print(f\"Stock {stock} returned a NaN validation gain\")\n",
        "            else:\n",
        "                print(f\"Stock {stock} optimization returned None\")\n",
        "        else:\n",
        "            print(f\"Stock {stock} has insufficient data for optimization\")\n",
        "\n",
        "    if manual_validation_gains:\n",
        "        average_manual_gain = sum(manual_validation_gains) / len(manual_validation_gains)\n",
        "    else:\n",
        "        average_manual_gain = np.nan\n",
        "\n",
        "    print(f\"Average %gain after ante for validation sets across all stocks: {average_manual_gain}\")\n",
        "\n",
        "    return manual_params, manual_validation_gains, average_manual_gain\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CXnARBWzt6Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run manual optimization\n",
        "manual_params, manual_validation_gains, average_manual_gain = manual_optimize(all_days=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XuN6ad6r0grb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title save parameters\n",
        "output_csv = 'optimization_results.csv'\n",
        "\n",
        "\n",
        "# Prepare data for writing\n",
        "data = [\n",
        "    [\"Portfolio Optimize\"],\n",
        "    [\"poscallbuy\", poscallbuy],\n",
        "    [\"poscallsell\", poscallsell],\n",
        "    [\"posputsell\", posputsell],\n",
        "    [\"posputbuy\", posputbuy],\n",
        "    [\"negcallbuy\", negcallbuy],\n",
        "    [\"negcallsell\", negcallsell],\n",
        "    [\"negputsell\", negputsell],\n",
        "    [\"negputbuy\", negputbuy],\n",
        "    [\"train_gain_pos_ante\", train_gain_pos_ante],\n",
        "    [\"train_gain_neg_ante\", train_gain_neg_ante],\n",
        "    [\"val_gain_pos_ante\", val_gain_pos_ante],\n",
        "    [\"val_gain_neg_ante\", val_gain_neg_ante],\n",
        "    [],\n",
        "    [\"Individual Optimize\"],\n",
        "    [\"optimized_params\", str(optimized_params)],\n",
        "    [\"validation_gains\", str(validation_gains)],\n",
        "    [\"average_validation_gain\", average_validation_gain],\n",
        "    [],\n",
        "    [\"Manual Optimize\"],\n",
        "    [\"manual_params\", str(manual_params)],\n",
        "    [\"manual_validation_gains\", str(manual_validation_gains)],\n",
        "    [\"average_manual_gain\", average_manual_gain]\n",
        "]\n",
        "\n",
        "# Write data to CSV\n",
        "with open(output_csv, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(data)\n",
        "\n",
        "print(f\"Results saved to {output_csv}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SPM-_JVbBq7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "outputId": "7241f012-e59c-4572-88d1-133dedaa8d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_gain_pos_ante' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-fe047e43983c>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"negputsell\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegputsell\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"negputbuy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegputbuy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"train_gain_pos_ante\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gain_pos_ante\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"train_gain_neg_ante\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gain_neg_ante\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"val_gain_pos_ante\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gain_pos_ante\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_gain_pos_ante' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poscallbuy = 0.13842\n",
        "poscallsell = -0.01\n",
        "posputsell = -0.1\n",
        "posputbuy = -0.01\n",
        "negcallbuy = 0.1282\n",
        "negcallsell = -0.13\n",
        "negputsell = -0.08\n",
        "negputbuy = -0.2\n",
        "optimized_params = {'ABNB': (0.005, None, -0.01, -0.16), 'AFRM': (0.005, None, -0.049999999999999996, -0.13), 'AMAT': (0.2, -0.11000000000000001, None, -0.03), 'AMD': (0.11789473684210527, -0.12000000000000001, None, -0.19), 'APA': (0.005, None, -0.049999999999999996, -0.13), 'CAVA': (0.005, -0.020000000000000018, -0.049999999999999996, -0.13), 'CCL': (0.13842105263157894, -0.19, None, -0.06), 'COIN': (0.11789473684210527, -0.12000000000000001, None, -0.19), 'CROX': (0.13842105263157894, -0.19, None, -0.06), 'CVNA': (0.005, None, -0.01, -0.16), 'CZR': (0.005, None, -0.01, -0.16), 'DASH': (0.005, None, -0.01, -0.16), 'DFS': (0.005, None, -0.01, -0.16), 'GPS': (0.005, None, -0.01, -0.16), 'KLAC': (0.2, -0.11000000000000001, None, -0.03), 'LRCX': (0.18973684210526315, -0.2, None, -0.01), 'MGM': (0.005, None, -0.01, -0.16), 'MRVL': (0.2, -0.11000000000000001, None, -0.03), 'MSTR': (0.18973684210526315, -0.2, None, -0.01), 'NVDA': (0.18973684210526315, -0.2, None, -0.01), 'ON': (0.11789473684210527, -0.12000000000000001, None, -0.19), 'PATH': (0.1281578947368421, None, -0.039999999999999994, -0.2), 'PINS': (0.005, None, -0.01, -0.16), 'RBLX': (0.025526315789473685, -0.07, -0.1, -0.06), 'RIVN': (0.005, None, -0.01, -0.16), 'RKT': (0.13842105263157894, None, -0.1, -0.06), 'SQ': (0.005, None, -0.01, -0.16), 'TOST': (0.005, None, -0.01, -0.16), 'TPR': (0.11789473684210527, -0.12000000000000001, None, -0.19), 'TSLA': (0.015263157894736843, -0.08000000000000002, -0.07, -0.01), 'TTD': (0.2, -0.11000000000000001, None, -0.03), 'W': (0.005, None, -0.01, -0.16)}\n",
        "manual_params = {'ABNB': (0.004647348277747376, -0.7061235647895024, -0.7266265718972116), 'AFRM': (0.012978790756568603, -0.20861031972143085, -0.33523266856600187), 'AMAT': (0.037047632670576425, -0.8378868068468984, -0.8426548419396367), 'AMD': (0.053185887309110225, -0.07846234860452861, -0.21011058451816744), 'APA': (0.0039499670836076195, -0.14417379855167867, -0.17709019091507572), 'CAVA': (0.011761730112558544, -0.4308840268116858, -0.49411913494372073), 'CCL': (0.07415107415107425, -0.13374913374913378, -0.23769923769923773), 'COIN': (0.04519211626518027, -0.5769460481783795, -0.7013736810670914), 'CROX': (0.026034759544915076, -0.9267118028896489, -0.9302017170377609), 'CVNA': (0.008547008547008517, -0.5726495726495726, -0.6581196581196581), 'CZR': (0.008844665561083431, -0.19845218352681038, -0.2260917634051962), 'DASH': (0.0013932427725531493, -0.7910135841170324, -0.8258446534308603), 'DFS': (0.004862236628849326, -0.08427876823338742, -0.12479740680713136), 'GPS': (0.010544815465729274, -0.2970123022847101, -0.34094903339191573), 'KLAC': (0.016330906205187512, -0.9331727623317136, -0.9373494646859816), 'LRCX': (0.015927115422429194, -0.79244499792445, -0.8306788140962618), 'MGM': (0.010598964752279949, -0.7535124476213951, -0.7658368252403254), 'MRVL': (0.05155542573389815, -0.2697531765736819, -0.34277785891631374), 'MSTR': (0.003828950935212738, -0.9237598265112497, -0.9279953917050692), 'NVDA': (0.012483588864905748, -0.9877611873873473, -0.9899864260441933), 'ON': (0.050241271643485685, -0.2903775191598069, -0.3613397672438262), 'PATH': (0.0926118626430803, -0.16753381893860553, -0.24557752341311134), 'PINS': (0.03571428571428581, -0.40476190476190477, -0.4285714285714286), 'RBLX': (0.049284578696343395, -0.20508744038155802, -0.3322734499205088), 'RIVN': (0.0010010010010010895, -0.4494494494494494, -0.49949949949949946), 'RKT': (0.024140453547915053, -0.30504754937820044, -0.3416239941477688), 'SQ': (0.009676062263357155, -0.22871967465993548, -0.2988360678726687), 'TOST': (0.006336190831159216, -0.3663809168840849, -0.4036526276556094), 'TPR': (0.0731220364362366, -0.10157224856501124, -0.1265285749937609), 'TSLA': (0.05360004748619929, -0.7032112542292397, -0.7328901288063157), 'TTD': (0.042860417144166885, -0.7134998853999541, -0.7192298876919552), 'W': (0.0039592760180995334, -0.4343891402714932, -0.5050904977375565)}\n",
        "all_stocks = list(set(all_stocks) & set(optimized_params.keys()))\n",
        "print(sorted(all_stocks))"
      ],
      "metadata": {
        "id": "D0W22_vvEGXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b3d7aa-fb0b-47e6-d347-b9120ba35ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ABNB', 'AFRM', 'AMAT', 'AMD', 'APA', 'CAVA', 'CCL', 'COIN', 'CROX', 'CVNA', 'CZR', 'DASH', 'DFS', 'GPS', 'KLAC', 'LRCX', 'MGM', 'MRVL', 'MSTR', 'NVDA', 'ON', 'PATH', 'PINS', 'RBLX', 'RIVN', 'RKT', 'SQ', 'TOST', 'TPR', 'TSLA', 'TTD', 'W']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gDosNx-ga-K",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title get_pdf\n",
        "def get_pdf(individual_csv_dir, individual_pdf_dir, final_pdf_path, manual_params, optimized_params, poscallbuy, poscallsell, posputsell, posputbuy, negcallbuy, negcallsell, negputsell, negputbuy, all_days):\n",
        "    # Define paths\n",
        "    os.makedirs(individual_csv_dir, exist_ok=True)\n",
        "    os.makedirs(individual_pdf_dir, exist_ok=True)\n",
        "\n",
        "    # Read the main data file\n",
        "    df = pd.read_csv(main_data_file_path)\n",
        "\n",
        "    # Function to round numerical values in the DataFrame\n",
        "    def round_df(df):\n",
        "        for col in df.columns:\n",
        "            df[col] = df[col].apply(lambda x: round(float(x), 3) if is_number(x) else x)\n",
        "\n",
        "        # Round specific cells to nearest dollar or 2 decimals as specified\n",
        "        dollar_columns = ['Strike', '% change','5 day option price', 'Column 5', 'Column 6']\n",
        "        dollar_rows = range(10, 17)\n",
        "        for col in dollar_columns:\n",
        "            for row in dollar_rows:\n",
        "                if col in df.columns and is_number(df.at[row, col]):\n",
        "                    df.at[row, col] = round(float(df.at[row, col]))\n",
        "\n",
        "        specific_cells = [\n",
        "            (0, 'Strike'), (1, 'Strike'), (2, 'Strike'), (3, 'Strike'), (4, 'Strike'), (6, 'Strike'),\n",
        "            (1, '5 day option price'), (2, '5 day option price'), (3, '5 day option price'), (4, '5 day option price'), (5,'5 day option price')\n",
        "        ]\n",
        "        for row, col in specific_cells:\n",
        "            if col in df.columns and is_number(df.at[row, col]):\n",
        "                df.at[row, col] = round(float(df.at[row, col]), 2)\n",
        "\n",
        "        percent_cells = [\n",
        "            (1, '% change'), (2, '% change'), (3, '% change'), (4, '% change'), (5, '% change'), (6, '% change')\n",
        "        ]\n",
        "        for row, col in percent_cells:\n",
        "            if col in df.columns and is_number(df.at[row, col]):\n",
        "                df.at[row, col] = f\"{round(float(df.at[row, col]) * 100, 2)}%\"\n",
        "\n",
        "        percent_columns = ['Strike', '% change','5 day option price', 'Column 6']\n",
        "        percent_rows = range(19,26)\n",
        "        for col in percent_columns:\n",
        "            for row in percent_rows:\n",
        "                if col in df.columns and is_number(df.at[row, col]):\n",
        "                    df.at[row, col] = f\"{round(float(df.at[row, col]) * 100, 2)}%\"\n",
        "\n",
        "        percent_columns = ['Strike', '% change','5 day option price']\n",
        "        percent_rows = range(28,35)\n",
        "        for col in percent_columns:\n",
        "            for row in percent_rows:\n",
        "                if col in df.columns and is_number(df.at[row, col]):\n",
        "                    df.at[row, col] = f\"{round(float(df.at[row, col]) * 100, 2)}%\"\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    # Helper function to check if a value is a number\n",
        "    def is_number(value):\n",
        "        try:\n",
        "            float(value)\n",
        "            return True\n",
        "        except (ValueError, TypeError):\n",
        "            return False\n",
        "\n",
        "    def add_label(df, label):\n",
        "        # Create a label row\n",
        "        label_row = pd.DataFrame([[label] + [''] * (df.shape[1] - 1)], columns=df.columns)\n",
        "        # Concatenate the label row with the DataFrame\n",
        "        labeled_df = pd.concat([label_row, df], ignore_index=True)\n",
        "        return labeled_df\n",
        "\n",
        "\n",
        "    def csv_to_pdf(csv_path, pdf_path, fontsize=10):\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        # Replace NaN values with empty strings\n",
        "        df = df.fillna('')\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))  # Adjust size as needed\n",
        "        ax.axis('tight')\n",
        "        ax.axis('off')\n",
        "        table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center')\n",
        "\n",
        "        # Set font size for the table\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(fontsize)\n",
        "\n",
        "        # Highlight the top left cell if ante is positive\n",
        "        if not df.iloc[6, 2].startswith('-'):\n",
        "            cell = table[0, 0]\n",
        "            cell.set_facecolor('green')\n",
        "            cell.set_text_props(color='white')\n",
        "\n",
        "        # Set specific width for the first column and enable text wrapping\n",
        "        cell_dict = table.get_celld()\n",
        "        for i in range(len(df.index) + 1):\n",
        "            cell_dict[(i, 0)].set_width(0.25)\n",
        "            cell_dict[(i, 0)].get_text().set_wrap(True)\n",
        "\n",
        "        # Set borders and linewidth\n",
        "        for key, cell in table.get_celld().items():\n",
        "            cell.set_edgecolor('black')\n",
        "            cell.set_linewidth(0.5)\n",
        "\n",
        "        # Extract relevant values, check for None\n",
        "        def parse_float(value):\n",
        "            try:\n",
        "                return float(value)\n",
        "            except ValueError:\n",
        "                return None\n",
        "\n",
        "        pp = PdfPages(pdf_path)\n",
        "        pp.savefig(fig, bbox_inches='tight')\n",
        "        pp.close()\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "    def merge_pdfs(pdf_list, output_path):\n",
        "        merger = PyPDF2.PdfMerger()\n",
        "        for pdf in pdf_list:\n",
        "            merger.append(pdf)\n",
        "        merger.write(output_path)\n",
        "        merger.close()\n",
        "\n",
        "    pdf_files = []\n",
        "\n",
        "    # Assuming all_stocks is already defined\n",
        "    for stock in all_stocks:\n",
        "        manual_df = get_df(stock, manual_params[stock][0], None, manual_params[stock][1], manual_params[stock][2], all_days)\n",
        "        individual_df = get_df(stock, optimized_params[stock][0], optimized_params[stock][1], optimized_params[stock][2], optimized_params[stock][3], all_days)\n",
        "        pos_portfolio_df = get_df(stock, poscallbuy, poscallsell, posputsell, posputbuy, all_days)\n",
        "        neg_portfolio_df = get_df(stock, negcallbuy, negcallsell, negputsell, negputbuy, all_days)\n",
        "        if pos_portfolio_df.iloc[time_frame,5] > neg_portfolio_df.iloc[time_frame,5]:\n",
        "            portfolio_df = pos_portfolio_df\n",
        "        else:\n",
        "            portfolio_df = neg_portfolio_df\n",
        "\n",
        "        manual_df = round_df(manual_df)\n",
        "        individual_df = round_df(individual_df)\n",
        "        portfolio_df = round_df(portfolio_df)\n",
        "\n",
        "        # Add labels to each DataFrame\n",
        "        manual_df = add_label(manual_df, 'Manual Selection')\n",
        "        individual_df = add_label(individual_df, 'Learned Stock')\n",
        "        portfolio_df = add_label(portfolio_df, 'Learned Portfolio')\n",
        "\n",
        "        # Save to CSV\n",
        "        csv_manual_path = os.path.join(individual_csv_dir, f'{stock}_manual_{today_date_str}_{expr_date_str}.csv')\n",
        "        manual_df.to_csv(csv_manual_path, index=False)\n",
        "        csv_individual_path = os.path.join(individual_csv_dir, f'{stock}_individual_{today_date_str}_{expr_date_str}.csv')\n",
        "        individual_df.to_csv(csv_individual_path, index=False)\n",
        "        csv_portfolio_path = os.path.join(individual_csv_dir, f'{stock}_portfolio_{today_date_str}_{expr_date_str}.csv')\n",
        "        portfolio_df.to_csv(csv_portfolio_path, index=False)\n",
        "\n",
        "        # Convert CSV to PDF\n",
        "        pdf_manual_path = os.path.join(individual_pdf_dir, f'{stock}_manual_{today_date_str}_{expr_date_str}.pdf')\n",
        "        csv_to_pdf(csv_manual_path, pdf_manual_path, fontsize=10)\n",
        "        pdf_individual_path = os.path.join(individual_csv_dir, f'{stock}_individual_{today_date_str}_{expr_date_str}.pdf')\n",
        "        csv_to_pdf(csv_individual_path, pdf_individual_path, fontsize=10)\n",
        "        pdf_portfolio_path = os.path.join(individual_csv_dir, f'{stock}_portfolio_{today_date_str}_{expr_date_str}.pdf')\n",
        "        csv_to_pdf(csv_portfolio_path, pdf_portfolio_path, fontsize=10)\n",
        "\n",
        "        pdf_files.append(pdf_manual_path)\n",
        "        pdf_files.append(pdf_individual_path)\n",
        "        pdf_files.append(pdf_portfolio_path)\n",
        "\n",
        "    # Merge all PDFs into one\n",
        "    merge_pdfs(pdf_files, final_pdf_path)\n",
        "    print(f\"All PDFs merged into {final_pdf_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run get_pdf\n",
        "get_pdf('individual_csvs', 'individual_pdfs', f'SignalDays_{today_date_str}_{expr_date_str}.pdf', manual_params, optimized_params, poscallbuy, poscallsell, posputsell, posputbuy, negcallbuy, negcallsell, negputsell, negputbuy, all_days=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNCuYaPx4Fl-",
        "outputId": "27c8e541-dcfc-4f23-980e-c3a765b77c34",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All PDFs merged into SignalDays_05-24-2024_05-31-2024.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N51rhozYj8g9",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7251817-9a34-4af6-8064-66f213d0c71c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the return threshold percentage (e.g., 10 for 10%) or press Enter to include all trades: \n",
            "Final trades saved to final_trades.csv\n"
          ]
        }
      ],
      "source": [
        "#@title get recommendations\n",
        "\n",
        "# Function to get user input for threshold\n",
        "def get_return_threshold():\n",
        "    while True:\n",
        "        threshold_input = input(\"Enter the return threshold percentage (e.g., 10 for 10%) or press Enter to include all trades: \")\n",
        "        if threshold_input == \"\":\n",
        "            return None\n",
        "        try:\n",
        "            return float(threshold_input) / 100\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number or press Enter to include all trades.\")\n",
        "\n",
        "# Get the return threshold\n",
        "return_threshold = get_return_threshold()\n",
        "\n",
        "# Initialize the final list of trades\n",
        "final_trades = []\n",
        "\n",
        "# Assuming all_stocks is already defined\n",
        "for stock in all_stocks:\n",
        "\n",
        "    # Generate DataFrames for the stock\n",
        "    manual_df = get_df(stock, manual_params[stock][0], None, manual_params[stock][1], manual_params[stock][2])\n",
        "    individual_df = get_df(stock, optimized_params[stock][0], optimized_params[stock][1], optimized_params[stock][2], optimized_params[stock][3])\n",
        "    pos_portfolio_df = get_df(stock, poscallbuy, poscallsell, posputsell, posputbuy)\n",
        "    neg_portfolio_df = get_df(stock, negcallbuy, negcallsell, negputsell, negputbuy)\n",
        "\n",
        "    if pos_portfolio_df.iloc[time_frame, 5] > neg_portfolio_df.iloc[time_frame, 5]:\n",
        "        portfolio_df = pos_portfolio_df\n",
        "    else:\n",
        "        portfolio_df = neg_portfolio_df\n",
        "\n",
        "    # Find the trades for the current stock\n",
        "    trades = [\n",
        "        ('Manual Selection', manual_df),\n",
        "        ('Learned Stock', individual_df),\n",
        "        ('Learned Portfolio', portfolio_df)\n",
        "    ]\n",
        "\n",
        "    for strategy_name, trade_df in trades:\n",
        "        trade_return = trade_df.iloc[time_frame, 5]\n",
        "\n",
        "        if return_threshold is None or trade_return > return_threshold:\n",
        "            call_buy_strike = trade_df.iloc[1, 1]\n",
        "            call_sell_strike = trade_df.iloc[2, 1]\n",
        "            put_sell_strike = trade_df.iloc[3, 1]\n",
        "            put_buy_strike = trade_df.iloc[4, 1]\n",
        "            ante = trade_df.iloc[5, 3]\n",
        "            projected_return = trade_return\n",
        "\n",
        "            final_trades.append({\n",
        "                'Stock': stock,\n",
        "                'Strategy': strategy_name,\n",
        "                'Call Buy Strike': call_buy_strike,\n",
        "                'Call Sell Strike': call_sell_strike,\n",
        "                'Put Sell Strike': put_sell_strike,\n",
        "                'Put Buy Strike': put_buy_strike,\n",
        "                'Ante': ante,\n",
        "                'Projected Return': projected_return\n",
        "            })\n",
        "\n",
        "# Define the CSV file path\n",
        "csv_file_path = 'final_trades.csv'\n",
        "\n",
        "# Write final trades to a CSV file\n",
        "with open(csv_file_path, mode='w', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=['Stock', 'Strategy', 'Call Buy Strike', 'Call Sell Strike', 'Put Sell Strike', 'Put Buy Strike', 'Ante', 'Projected Return'])\n",
        "    writer.writeheader()\n",
        "    for trade in final_trades:\n",
        "        writer.writerow(trade)\n",
        "\n",
        "print(f\"Final trades saved to {csv_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zIX5rurzpjQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run individual optimize (all days)\n",
        "all_optimized_params, all_validation_gains, all_average_validation_gain = individual_optimize(all_days=True)"
      ],
      "metadata": {
        "id": "kd9CPh1QhAzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a17ddde-8200-41fa-b449-36d1a3cbb94d",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average gain after ante for validation sets across all stocks: 16.78250738350836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run portfolio optimize (all days)\n",
        "all_train_gain_post_ante, all_train_gain_neg_ante, all_val_gain_pos_ante, all_val_gain_neg_ante, all_poscallbuy, all_poscallsell, all_posputsell, all_posputbuy, all_negcallbuy, all_negcallsell, all_negputsell, all_negputbuy = portfolio_optimize(all_days=True)"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "ezvqEzJHLeg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run manual optimization (all days)\n",
        "all_manual_params, all_manual_validation_gains, all_average_manual_gain = manual_optimize(all_days=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nULVd6gu1oXB",
        "outputId": "38d3e576-7006-43d4-d07d-6727f1b75fde",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average %gain after ante for validation sets across all stocks: -2.779186324253009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_poscallbuy = 0.0666\n",
        "all_poscallsell = -0.01\n",
        "all_posputsell = -0.1\n",
        "all_posputbuy = -0.03\n",
        "all_negcallbuy = 0.128\n",
        "all_negcallsell = -0.13\n",
        "all_negputsell = -0.08\n",
        "all_negputbuy = -0.2\n",
        "all_manual_params = {'ABNB': (0.004647348277747376, -0.7061235647895024, -0.7266265718972116), 'AFRM': (0.012978790756568603, -0.20861031972143085, -0.33523266856600187), 'AMAT': (0.037047632670576425, -0.8378868068468984, -0.8426548419396367), 'AMD': (0.053185887309110225, -0.07846234860452861, -0.21011058451816744), 'APA': (0.0039499670836076195, -0.14417379855167867, -0.17709019091507572), 'CAVA': (0.04970279499177943, -0.4308840268116858, -0.49411913494372073), 'CCL': (0.10880110880110871, -0.13374913374913378, -0.23769923769923773), 'COIN': (0.04519211626518027, -0.5769460481783795, -0.7013736810670914), 'CROX': (0.026034759544915076, -0.9267118028896489, -0.9302017170377609), 'CVNA': (0.008547008547008517, -0.5726495726495726, -0.6581196581196581), 'CZR': (0.008844665561083431, -0.19845218352681038, -0.2260917634051962), 'DASH': (0.0013932427725531493, -0.7910135841170324, -0.8258446534308603), 'DFS': (0.004862236628849326, -0.08427876823338742, -0.10048622366288495), 'GPS': (0.010544815465729274, -0.2970123022847101, -0.34094903339191573), 'KLAC': (0.016330906205187512, -0.9331727623317136, -0.9373494646859816), 'LRCX': (0.015927115422429194, -0.79244499792445, -0.8306788140962618), 'MGM': (0.010598964752279949, -0.7535124476213951, -0.7658368252403254), 'MRVL': (0.05155542573389815, -0.2697531765736819, -0.34277785891631374), 'MSTR': (0.016535646516671276, -0.9237598265112497, -0.9279953917050692), 'NVDA': (0.012483588864905748, -0.9877611873873473, -0.9899864260441933), 'ON': (0.050241271643485685, -0.2903775191598069, -0.3613397672438262), 'PATH': (0.0926118626430803, -0.16753381893860553, -0.24557752341311134), 'PINS': (0.011904761904761862, -0.40476190476190477, -0.4285714285714286), 'RBLX': (0.049284578696343395, -0.20508744038155802, -0.3322734499205088), 'RIVN': (0.10110110110110115, -0.4494494494494494, -0.49949949949949946), 'RKT': (0.09729334308705195, -0.30504754937820044, -0.3416239941477688), 'SQ': (0.009676062263357155, -0.22871967465993548, -0.2988360678726687), 'TOST': (0.006336190831159216, -0.3663809168840849, -0.4036526276556094), 'TPR': (0.09807836286498617, -0.10157224856501124, -0.1265285749937609), 'TSLA': (0.05360004748619929, -0.7032112542292397, -0.7328901288063157), 'TTD': (0.042860417144166885, -0.7134998853999541, -0.7192298876919552), 'W': (0.0039592760180995334, -0.4343891402714932, -0.5050904977375565)}\n",
        "all_optimized_params = {'ABNB': (0.005, None, -0.01, -0.16), 'AFRM': (0.005, None, -0.049999999999999996, -0.13), 'AMAT': (0.2, -0.11000000000000001, None, -0.03), 'AMD': (0.11789473684210527, -0.12000000000000001, None, -0.19), 'APA': (0.18973684210526315, None, -0.1, -0.01), 'CAVA': (0.15894736842105264, -0.17, -0.03, -0.09000000000000001), 'CCL': (0.13842105263157894, -0.19, None, -0.06), 'COIN': (0.18973684210526315, -0.2, None, -0.01), 'CROX': (0.13842105263157894, -0.19, None, -0.06), 'CVNA': (0.005, None, -0.01, -0.16), 'CZR': (0.005, None, -0.01, -0.16), 'DASH': (0.005, None, -0.01, -0.16), 'DFS': (0.005, -0.020000000000000018, -0.049999999999999996, -0.13), 'GPS': (0.005, None, -0.01, -0.16), 'KLAC': (0.2, -0.11000000000000001, None, -0.03), 'LRCX': (0.18973684210526315, -0.2, None, -0.01), 'MGM': (0.005, None, -0.01, -0.16), 'MRVL': (0.2, -0.11000000000000001, None, -0.03), 'MSTR': (0.2, -0.11000000000000001, None, -0.03), 'NVDA': (0.18973684210526315, -0.2, None, -0.01), 'ON': (0.11789473684210527, -0.12000000000000001, None, -0.19), 'PATH': (0.005, -0.020000000000000018, -0.049999999999999996, -0.13), 'PINS': (0.005, None, -0.01, -0.16), 'RBLX': (0.025526315789473685, -0.07, -0.1, -0.06), 'RIVN': (0.09736842105263158, -0.03, -0.039999999999999994, -0.11000000000000001), 'RKT': (0.025526315789473685, -0.07, -0.1, -0.06), 'SQ': (0.005, None, -0.01, -0.16), 'TOST': (0.005, None, -0.01, -0.16), 'TPR': (0.11789473684210527, -0.12000000000000001, None, -0.19), 'TSLA': (0.1281578947368421, -0.08000000000000002, None, -0.2), 'TTD': (0.2, -0.11000000000000001, None, -0.03), 'W': (0.005, None, -0.01, -0.16)}"
      ],
      "metadata": {
        "id": "Uh0XL5tuKy_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run get_pdf\n",
        "get_pdf('alldays_csvs', 'alldays_pdfs', f'AllDays_{today_date_str}_{expr_date_str}.pdf', all_manual_params, all_optimized_params, all_poscallbuy, all_poscallsell, all_posputsell, all_posputbuy, all_negcallbuy, all_negcallsell, all_negputsell, all_negputbuy, all_days=True)"
      ],
      "metadata": {
        "id": "7FETwyfsiwoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb01147-8716-448f-96ec-ecad0888bb0f",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All PDFs merged into AllDays_05-31-2024_2024-06-14.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Are the signal days better than the average day?\n",
        "# Define paths\n",
        "individual_csv_dir_signal = 'individual_csvs'\n",
        "individual_csv_dir_all_days = 'alldays_csvs'\n",
        "\n",
        "results_dir = 'results'\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Helper function to check if a value is a number\n",
        "def is_number(value):\n",
        "    try:\n",
        "        float(value.strip('%')) / 100.0\n",
        "        return True\n",
        "    except (ValueError, TypeError):\n",
        "        return False\n",
        "\n",
        "# Extract average returns from CSV files\n",
        "def extract_average_returns(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    averages = {}\n",
        "    time_frames = {\n",
        "        '1 Mo': 20,\n",
        "        'YTD': 21,\n",
        "        'TTM': 22,\n",
        "        '2023': 23,\n",
        "        '2022': 24,\n",
        "        '2021': 25,\n",
        "        'All': 26\n",
        "    }\n",
        "    for tf, row in time_frames.items():\n",
        "        value = df.iloc[row, 5]\n",
        "        num = float(df.iloc[row, 4])\n",
        "        if is_number(value) and num != 0:\n",
        "            averages[tf] = (float(value.strip('%')) / 100.0) / num\n",
        "        else:\n",
        "            averages[tf] = 0\n",
        "    return averages\n",
        "\n",
        "# Initialize a list to hold the results for each strategy\n",
        "results_manual = []\n",
        "results_individual = []\n",
        "results_portfolio = []\n",
        "\n",
        "# Assuming all_stocks is already defined\n",
        "for stock in all_stocks:\n",
        "    for strategy in ['manual', 'individual', 'portfolio']:\n",
        "        # Paths to CSV files\n",
        "        csv_signal_path = os.path.join(individual_csv_dir_signal, f'{stock}_{strategy}_{today_date_str}_{expr_date_str}.csv')\n",
        "        csv_all_days_path = os.path.join(individual_csv_dir_all_days, f'{stock}_{strategy}_{today_date_str}_{expr_date_str}.csv')\n",
        "\n",
        "        if os.path.exists(csv_signal_path) and os.path.exists(csv_all_days_path):\n",
        "            # Extract average returns for signal days and all days\n",
        "            signal_averages = extract_average_returns(csv_signal_path)\n",
        "            all_days_averages = extract_average_returns(csv_all_days_path)\n",
        "\n",
        "            # Append the results to the appropriate list\n",
        "            result = {\n",
        "                'Stock': stock,\n",
        "                **{f'Signal {tf}': signal_averages[tf] for tf in signal_averages},\n",
        "                **{f'All Days {tf}': all_days_averages[tf] for tf in all_days_averages}\n",
        "            }\n",
        "\n",
        "            if strategy == 'manual':\n",
        "                results_manual.append(result)\n",
        "            elif strategy == 'individual':\n",
        "                results_individual.append(result)\n",
        "            elif strategy == 'portfolio':\n",
        "                results_portfolio.append(result)\n",
        "\n",
        "# Convert the results to DataFrames\n",
        "results_df_manual = pd.DataFrame(results_manual)\n",
        "results_df_individual = pd.DataFrame(results_individual)\n",
        "results_df_portfolio = pd.DataFrame(results_portfolio)\n",
        "\n",
        "# Restructure the columns\n",
        "time_frames = ['1 Mo', 'YTD', 'TTM', '2023', '2022', '2021', 'All']\n",
        "ordered_columns = ['Stock']\n",
        "for tf in time_frames:\n",
        "    ordered_columns.append(f'Signal {tf}')\n",
        "    ordered_columns.append(f'All Days {tf}')\n",
        "\n",
        "results_df_manual = results_df_manual[ordered_columns]\n",
        "results_df_individual = results_df_individual[ordered_columns]\n",
        "results_df_portfolio = results_df_portfolio[ordered_columns]\n",
        "\n",
        "\n",
        "# Calculate the sum of returns for each time period\n",
        "def add_sum_row(df):\n",
        "    sum_row = {col: df[col].sum() if df[col].dtype in [float, int] else '' for col in df.columns}\n",
        "    sum_row['Stock'] = 'Total'\n",
        "    return pd.concat([pd.DataFrame([sum_row]), df], ignore_index=True)\n",
        "\n",
        "results_df_manual = add_sum_row(results_df_manual)\n",
        "results_df_individual = add_sum_row(results_df_individual)\n",
        "results_df_portfolio = add_sum_row(results_df_portfolio)\n",
        "\n",
        "# Round all values to 3 decimal points\n",
        "results_df_manual = results_df_manual.round(3)\n",
        "results_df_individual = results_df_individual.round(3)\n",
        "results_df_portfolio = results_df_portfolio.round(3)\n",
        "\n",
        "\n",
        "results_csv_path_manual = os.path.join(results_dir, 'average_returns_manual.csv')\n",
        "results_csv_path_individual = os.path.join(results_dir, 'average_returns_individual.csv')\n",
        "results_csv_path_portfolio = os.path.join(results_dir, 'average_returns_portfolio.csv')\n",
        "\n",
        "# Save the results to CSV files\n",
        "if not results_df_manual.empty:\n",
        "    results_df_manual.to_csv(results_csv_path_manual, index=False)\n",
        "    print(f\"Average returns saved to {results_csv_path_manual}\")\n",
        "\n",
        "if not results_df_individual.empty:\n",
        "    results_df_individual.to_csv(results_csv_path_individual, index=False)\n",
        "    print(f\"Average returns saved to {results_csv_path_individual}\")\n",
        "\n",
        "if not results_df_portfolio.empty:\n",
        "    results_df_portfolio.to_csv(results_csv_path_portfolio, index=False)\n",
        "    print(f\"Average returns saved to {results_csv_path_portfolio}\")\n",
        "\n",
        "# Function to create highlighted PDF\n",
        "def create_highlighted_pdf(results_df, pdf_path, strategy_name):\n",
        "    if results_df.empty:\n",
        "        print(f\"No data to create PDF for {strategy_name}\")\n",
        "        return\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    table = ax.table(cellText=results_df.values, colLabels=results_df.columns, cellLoc='center', loc='center')\n",
        "\n",
        "    # Highlight the better returns\n",
        "    for i in range(1, len(results_df.columns), 2):\n",
        "        for j in range(len(results_df)):\n",
        "            signal_value = results_df.iloc[j, i]\n",
        "            all_days_value = results_df.iloc[j, i + 1]\n",
        "            if signal_value > all_days_value:\n",
        "                table[(j + 1, i)].set_facecolor('lightgreen')\n",
        "            elif all_days_value > signal_value:\n",
        "                table[(j + 1, i + 1)].set_facecolor('lightcoral')\n",
        "\n",
        "    plt.title(f'{strategy_name} Average Returns Comparison')\n",
        "    pp = PdfPages(pdf_path)\n",
        "    pp.savefig(fig, bbox_inches='tight')\n",
        "    pp.close()\n",
        "    plt.close(fig)\n",
        "\n",
        "# Define the PDF file paths\n",
        "results_pdf_path_manual = os.path.join(results_dir, 'average_returns_manual.pdf')\n",
        "results_pdf_path_individual = os.path.join(results_dir, 'average_returns_individual.pdf')\n",
        "results_pdf_path_portfolio = os.path.join(results_dir, 'average_returns_portfolio.pdf')\n",
        "\n",
        "# Create PDFs with highlighted better returns\n",
        "create_highlighted_pdf(results_df_manual, results_pdf_path_manual, 'Manual')\n",
        "create_highlighted_pdf(results_df_individual, results_pdf_path_individual, 'Individual')\n",
        "create_highlighted_pdf(results_df_portfolio, results_pdf_path_portfolio, 'Portfolio')\n",
        "\n",
        "\n",
        "# Function to merge PDFs\n",
        "def merge_pdfs(pdf_list, output_path):\n",
        "    merger = PyPDF2.PdfMerger()\n",
        "    for pdf in pdf_list:\n",
        "        merger.append(pdf)\n",
        "    merger.write(output_path)\n",
        "    merger.close()\n",
        "\n",
        "# Merge all PDFs into one\n",
        "final_pdf_path = 'average_returns_combined.pdf'\n",
        "pdf_files = [results_pdf_path_manual, results_pdf_path_individual, results_pdf_path_portfolio]\n",
        "merge_pdfs(pdf_files, final_pdf_path)\n",
        "print(f\"All PDFs merged into {final_pdf_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Y5gcwGw-eFaP",
        "outputId": "8d4ecd36-a10e-4a68-a6cc-8792a0285b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average returns saved to results/average_returns_manual.csv\n",
            "Average returns saved to results/average_returns_individual.csv\n",
            "Average returns saved to results/average_returns_portfolio.csv\n",
            "All PDFs merged into average_returns_combined.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Graphing\n",
        "# Function to upload multiple CSV files\n",
        "def upload_files():\n",
        "    uploaded = files.upload()\n",
        "    file_paths = list(uploaded.keys())\n",
        "    return file_paths\n",
        "\n",
        "# Function to compute the center of a cluster\n",
        "def compute_center(data):\n",
        "    return data.mean()\n",
        "\n",
        "# Function to compute variance\n",
        "def compute_variance(data):\n",
        "    return data.var()\n",
        "\n",
        "# Get user inputs for percentage and ante thresholds\n",
        "def get_user_inputs():\n",
        "    percentage_threshold = float(input(\"Enter the percentage threshold: \"))\n",
        "    ante_threshold = float(input(\"Enter the ante threshold: \"))\n",
        "    variance_threshold = float(input(\"Enter the variance threshold: \"))\n",
        "    return percentage_threshold, ante_threshold, variance_threshold\n",
        "\n",
        "# Upload the CSV files\n",
        "print(\"Please upload the CSV files.\")\n",
        "csv_file_paths = upload_files()\n",
        "\n",
        "# Initialize a dictionary to hold the aggregated data for each stock\n",
        "stock_data = {}\n",
        "\n",
        "# Process each uploaded CSV file\n",
        "for file_path in csv_file_paths:\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Ensure 'Ante' and 'Projected Return' columns are numeric\n",
        "    df['Ante'] = pd.to_numeric(df['Ante'], errors='coerce')\n",
        "    df['Projected Return'] = pd.to_numeric(df['Projected Return'], errors='coerce')\n",
        "\n",
        "    # Group data by stock\n",
        "    for stock, group in df.groupby('Stock'):\n",
        "        if stock not in stock_data:\n",
        "            stock_data[stock] = []\n",
        "        stock_data[stock].append(group)\n",
        "\n",
        "# Combine data for each stock\n",
        "for stock in stock_data:\n",
        "    stock_data[stock] = pd.concat(stock_data[stock])\n",
        "\n",
        "# Get user inputs\n",
        "percentage_threshold, ante_threshold, variance_threshold = get_user_inputs()\n",
        "\n",
        "# Initialize a dictionary to hold the filtered data\n",
        "filtered_stock_data = {}\n",
        "\n",
        "# Define colors for each strategy\n",
        "strategy_colors = {\n",
        "    'Manual Selection': 'red',\n",
        "    'Learned Stock': 'green',\n",
        "    'Learned Portfolio': 'blue'\n",
        "}\n",
        "\n",
        "# Define common axis limits\n",
        "min_ante = float('inf')\n",
        "max_ante = float('-inf')\n",
        "min_return = float('inf')\n",
        "max_return = float('-inf')\n",
        "\n",
        "# Calculate the common axis limits\n",
        "for stock, data in stock_data.items():\n",
        "    min_ante = min(min_ante, data['Ante'].min())\n",
        "    max_ante = max(max_ante, data['Ante'].max())\n",
        "    min_return = min(min_return, data['Projected Return'].min())\n",
        "    max_return = max(max_return, data['Projected Return'].max())\n",
        "\n",
        "# Create a directory to save the plots\n",
        "output_dir = 'stock_plots'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Create a PDF file to save the plots\n",
        "pdf_path = os.path.join(output_dir, 'stock_ante_vs_return.pdf')\n",
        "pdf = PdfPages(pdf_path)\n",
        "\n",
        "# Initialize a dictionary to hold the centers for each strategy and stock\n",
        "centers = {}\n",
        "\n",
        "# Plot the graphs for each stock\n",
        "for stock, data in stock_data.items():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Initialize the filtered data for this stock\n",
        "    filtered_stock_data[stock] = []\n",
        "\n",
        "    # Plot each strategy\n",
        "    for strategy, group in data.groupby('Strategy'):\n",
        "        ante_mean = group['Ante'].mean()\n",
        "        return_mean = group['Projected Return'].mean() * 100\n",
        "        variance = compute_variance(group['Projected Return'])\n",
        "\n",
        "        # Check the thresholds\n",
        "        if return_mean >= percentage_threshold and ante_mean >= ante_threshold and variance <= variance_threshold:\n",
        "            plt.scatter(group['Ante'], group['Projected Return'] * 100,\n",
        "                        color=strategy_colors.get(strategy, 'black'), label=strategy)\n",
        "\n",
        "            # Store the filtered data\n",
        "            filtered_stock_data[stock].append(group)\n",
        "\n",
        "            # Save the center of the cluster\n",
        "            if stock not in centers:\n",
        "                centers[stock] = []\n",
        "            centers[stock].append({'Strategy': strategy, 'Ante': ante_mean, 'Return': return_mean, 'Variance': variance})\n",
        "\n",
        "    plt.xlabel('Ante')\n",
        "    plt.ylabel('Projected Return (%)')\n",
        "    plt.title(f'{stock} - Ante vs. Projected Return')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xlim(min_ante, max_ante)\n",
        "    plt.ylim(min_return * 100, max_return * 100)\n",
        "\n",
        "    # Save the plot to the PDF\n",
        "    pdf.savefig()\n",
        "    plt.close()\n",
        "\n",
        "# Close the PDF file\n",
        "pdf.close()\n",
        "\n",
        "print(f\"Plots saved to {pdf_path}\")\n",
        "\n",
        "# Filter out the discarded strategies from the CSV files and save to new CSVs\n",
        "filtered_csv_dir = 'filtered_csvs'\n",
        "os.makedirs(filtered_csv_dir, exist_ok=True)\n",
        "\n",
        "for file_path in csv_file_paths:\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    filtered_df = pd.DataFrame()\n",
        "\n",
        "    # Group data by stock and strategy\n",
        "    for stock, group in df.groupby('Stock'):\n",
        "        if stock in centers:\n",
        "            for strategy in group['Strategy'].unique():\n",
        "                if any(center['Strategy'] == strategy for center in centers[stock]):\n",
        "                    filtered_df = pd.concat([filtered_df, group[group['Strategy'] == strategy]])\n",
        "\n",
        "    # Save the filtered data to a new CSV file\n",
        "    new_file_path = os.path.join(filtered_csv_dir, os.path.basename(file_path))\n",
        "    filtered_df.to_csv(new_file_path, index=False)\n",
        "\n",
        "print(f\"Filtered CSV files saved to {filtered_csv_dir}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "cellView": "form",
        "id": "ErTiqBMKP8_9",
        "outputId": "cbc9da56-3471-4661-b9b7-120460a71d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the CSV files.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8a3b2836-f907-4500-a0de-c7f28fb630f3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8a3b2836-f907-4500-a0de-c7f28fb630f3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving final_trades (2).csv to final_trades (2) (2).csv\n",
            "Enter the percentage threshold: 100\n",
            "Enter the ante threshold: 0\n",
            "Enter the variance threshold: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plots saved to stock_plots/stock_ante_vs_return.pdf\n",
            "Filtered CSV files saved to filtered_csvs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Actual returns\n",
        "# Function to calculate the actual return based on June 14th prices\n",
        "def calculate_actual_returns(trades_df, stock_prices):\n",
        "    actual_returns = []\n",
        "\n",
        "    for _, row in trades_df.iterrows():\n",
        "        stock = row['Stock']\n",
        "        strategy = row['Strategy']\n",
        "        call_buy_strike = row['Call Buy Strike']\n",
        "        call_sell_strike = row['Call Sell Strike']\n",
        "        put_sell_strike = row['Put Sell Strike']\n",
        "        put_buy_strike = row['Put Buy Strike']\n",
        "        ante = row['Ante']\n",
        "\n",
        "        stock_price = stock_prices.get(stock, None)\n",
        "\n",
        "        if stock_price is None:\n",
        "            actual_returns.append(None)\n",
        "            continue\n",
        "\n",
        "        # Calculate the return for each trade\n",
        "        if stock_price > call_buy_strike:\n",
        "            call_buy_return = stock_price - call_buy_strike\n",
        "        else:\n",
        "            call_buy_return = 0\n",
        "\n",
        "        if stock_price > call_sell_strike:\n",
        "            call_sell_return = stock_price - call_sell_strike\n",
        "        else:\n",
        "            call_sell_return = 0\n",
        "\n",
        "        if stock_price < put_sell_strike:\n",
        "            put_sell_return = put_sell_strike - stock_price\n",
        "        else:\n",
        "            put_sell_return = 0\n",
        "\n",
        "        if stock_price < put_buy_strike:\n",
        "            put_buy_return = put_buy_strike - stock_price\n",
        "        else:\n",
        "            put_buy_return = 0\n",
        "\n",
        "        total_return_dollars = call_buy_return - call_sell_return - put_sell_return + put_buy_return + ante\n",
        "        actual_returns.append(total_return_dollars)\n",
        "\n",
        "    trades_df['Actual Return'] = actual_returns\n",
        "    return trades_df\n",
        "\n",
        "\n",
        "# Define the dictionary of stock prices for June 14th\n",
        "# june_14th_prices = {\n",
        "#     'ABNB':145.97,\n",
        "#     'AFRM':30.90,\n",
        "#     'AMAT':237.03,\n",
        "#     'AMD':159.63,\n",
        "#     'APA':27.82,\n",
        "#     'CAVA':89.93,\n",
        "#     'CCL':15.34,\n",
        "#     'COIN':244.5,\n",
        "#     'CROX':156.98,\n",
        "#     'CVNA':103.06,\n",
        "#     'CZR':36.03,\n",
        "#     'DASH':112.05,\n",
        "#     'DFS':122,\n",
        "#     'GPS':24.99,\n",
        "#     'LRCX':1035.98,\n",
        "#     'MGM':39.85,\n",
        "#     'MRVL':73.27,\n",
        "#     'ON':71.97,\n",
        "#     'PATH':11.54,\n",
        "#     'PINS':43.51,\n",
        "#     'RBLX':35.1,\n",
        "#     'RIVN':10.88,\n",
        "#     'RKT':14.69,\n",
        "#     'SQ':62.15,\n",
        "#     'TOST':22.72,\n",
        "#     'TPR':41.81,\n",
        "#     'TSLA':178.01,\n",
        "#     'TTD':95.66,\n",
        "#     'W':52.62\n",
        "# }\n",
        "\n",
        "may_31_prices = {\n",
        "    'ABNB': 144.93,\n",
        "    'AFRM': 29.27,\n",
        "    'AMAT': 215.08,\n",
        "    'AMD': 166.9,\n",
        "    'APA': 30.53,\n",
        "    'CAVA': 92.55,\n",
        "    'CCL': 15.08,\n",
        "    'COIN': 225.92,\n",
        "    'CROX': 155.64,\n",
        "    'CVNA': 99.98,\n",
        "    'CZR': 35.56,\n",
        "    'DASH': 110.11,\n",
        "    'DFS': 122.66,\n",
        "    'GPS': 28.96,\n",
        "    'KLAC': 759.53,\n",
        "    'LRCX': 932.44,\n",
        "    'MGM': 40.17,\n",
        "    'MRVL': 68.81,\n",
        "    'MSTR': 1524.49,\n",
        "    'NVDA': 109.63,\n",
        "    'ON': 73.04,\n",
        "    'PATH': 12.26,\n",
        "    'PINS': 41.49,\n",
        "    'RBLX': 33.62,\n",
        "    'RIVN': 10.92,\n",
        "    'RKT': 13.9,\n",
        "    'SQ': 64.08,\n",
        "    'TOST': 24.23,\n",
        "    'TPR': 43.49,\n",
        "    'TSLA': 178.08,\n",
        "    'TTD': 92.78,\n",
        "    'W': 59.49\n",
        "\n",
        "\n",
        "}\n",
        "# Define the path for the final trades CSV\n",
        "final_trades_file_path = 'final_trades.csv'\n",
        "updated_csv_dir = 'updated_csvs'\n",
        "os.makedirs(updated_csv_dir, exist_ok=True)\n",
        "\n",
        "# Process the final trades CSV file\n",
        "trades_df = pd.read_csv(final_trades_file_path)\n",
        "trades_df = calculate_actual_returns(trades_df, may_31_prices)\n",
        "\n",
        "# Print the sum of actual returns for each strategy\n",
        "strategy_sums = trades_df.groupby('Strategy')['Actual Return'].sum()\n",
        "print(\"Sum of Actual Returns for each Strategy:\")\n",
        "print(strategy_sums)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "new_file_path = os.path.join(updated_csv_dir, os.path.basename(final_trades_file_path))\n",
        "trades_df.to_csv(new_file_path, index=False)\n",
        "\n",
        "print(f\"Updated CSV file with actual returns saved to {new_file_path}.\")\n",
        "\n",
        "# filtered_csv_dir = 'individual_csvs'\n",
        "# updated_csv_dir = 'updated_csvs'\n",
        "# os.makedirs(updated_csv_dir, exist_ok=True)\n",
        "\n",
        "# # Process each final trades CSV file\n",
        "# for file_name in os.listdir(filtered_csv_dir):\n",
        "#     file_path = os.path.join(filtered_csv_dir, file_name)\n",
        "#     trades_df = pd.read_csv(file_path)\n",
        "#     trades_df = calculate_actual_returns(trades_df, may_31_prices)\n",
        "\n",
        "#     # Save the updated DataFrame to a new CSV file\n",
        "#     new_file_path = os.path.join(updated_csv_dir, os.path.basename(file_path))\n",
        "#     trades_df.to_csv(new_file_path, index=False)\n",
        "\n",
        "# print(f\"Updated CSV files with actual returns saved to {updated_csv_dir}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUdJi_NcQW5b",
        "outputId": "c7652dd6-d9a7-4a86-8f9d-bdc3c093a089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of Actual Returns for each Strategy:\n",
            "Strategy\n",
            "Learned Portfolio     215.265\n",
            "Learned Stock        1088.595\n",
            "Manual Selection     -221.800\n",
            "Name: Actual Return, dtype: float64\n",
            "Updated CSV file with actual returns saved to updated_csvs/final_trades.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "z7GPP9xrjMvW"
      },
      "outputs": [],
      "source": [
        "#@title ignore (graphing maxloss)\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Define the parameters for your options\n",
        "# current_price = 100\n",
        "# call_buy_strike = 105\n",
        "# call_sell_strike = 110\n",
        "# put_buy_strike = 95\n",
        "# put_sell_strike = 90\n",
        "\n",
        "# # Define the range of stock prices to plot\n",
        "# prices = np.linspace(70, 130, 500)\n",
        "\n",
        "# # Calculate the payoff for each price point\n",
        "# def calculate_payoff(price, call_buy_strike, call_sell_strike, put_buy_strike, put_sell_strike):\n",
        "#     payoff = 0\n",
        "\n",
        "#     # Call buy\n",
        "#     if call_buy_strike is not None:\n",
        "#         payoff += max(price - call_buy_strike, 0)\n",
        "\n",
        "#     # Call sell\n",
        "#     if call_sell_strike is not None:\n",
        "#         payoff -= max(price - call_sell_strike, 0)\n",
        "\n",
        "#     # Put buy\n",
        "#     if put_buy_strike is not None:\n",
        "#         payoff += max(put_buy_strike - price, 0)\n",
        "\n",
        "#     # Put sell\n",
        "#     if put_sell_strike is not None:\n",
        "#         payoff -= max(put_sell_strike - price, 0)\n",
        "\n",
        "#     return payoff\n",
        "\n",
        "# payoffs = [calculate_payoff(price, call_buy_strike, call_sell_strike, put_buy_strike, put_sell_strike) for price in prices]\n",
        "\n",
        "# # Create the plot\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(prices, payoffs, label='Payoff')\n",
        "# plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
        "# plt.axvline(current_price, color='red', linestyle='--', linewidth=1, label='Current Price')\n",
        "# plt.axvline(call_buy_strike, color='green', linestyle='--', linewidth=1, label='Call Buy Strike')\n",
        "# plt.axvline(call_sell_strike, color='blue', linestyle='--', linewidth=1, label='Call Sell Strike')\n",
        "# plt.axvline(put_buy_strike, color='purple', linestyle='--', linewidth=1, label='Put Buy Strike')\n",
        "# plt.axvline(put_sell_strike, color='orange', linestyle='--', linewidth=1, label='Put Sell Strike')\n",
        "\n",
        "# # Add labels and title\n",
        "# plt.xlabel('Stock Price')\n",
        "# plt.ylabel('Payoff')\n",
        "# plt.title('Options Strategy Payoff Diagram')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2qf5CK1Wi5SEf2qmqPuUr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}